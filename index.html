<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>ROCLING 2024</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/favicon_io/favicon-32x32.png" rel="icon">
  <link href="img/favicon_io/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css" rel="stylesheet">

  <!-- Google Search Console -->
  <meta name="google-site-verification" content="-fD59RiHc4OQb37XpVtmZkcUeguaxVbKsDHtu6wsbQo" />
  
  <!-- =======================================================
    Theme Name: TheEvent
    Theme URL: https://bootstrapmade.com/theevent-conference-event-bootstrap-template/
    Author: BootstrapMade.com
    License: https://bootstrapmade.com/license/
  ======================================================= -->
</head>

<body>
  <!--==========================
    Header
  ============================-->
  <header id="header">
    <div class="container">
      <div id="logo" class="pull-left">
        <!-- Uncomment below if you prefer to use a text logo -->

        <a href="#intro" class="scrollto"><h2 style="color: purple;"><b>Rocling 2024</b></h2></a>
      </div>

      <nav id="nav-menu-container">
        <ul class="nav-menu">
          <li class="menu-active"><a href="#intro">Home</a></li>
          <!-- <li><a href="#photo">Photo</a></li> -->
          <li><a href="#call">Call for Papers</a></li>
          <li><a href="#schedule">Program</a></li>
<!--
          <li><a href="#speakers">Keynote Speakers</a></li>
          <li><a href="#task">Shared Task</a></li>
          <li><a href="#special">Special Session</a></li>
          <li><a href="#tutorial">AI Tutorial</a></li>
-->
          <li><a href="#buy-registrations">Registration</a></li>
          <li><a href="#organization">Organization</a></li>
          <li><a href="#venue">Venue</a></li>
          <li><a href="#sponsors">Sponsors</a></li>
          <li><a href="history.html" target="_blank">History</a></li>
<!--          <li class="highlight-button"><a href="https://aclanthology.org/events/rocling-2023/" target="_blank">Proceedings</a></li> -->
          
        </ul>
      </nav><!-- #nav-menu-container -->
    </div>
  </header><!-- #header -->

  <!--==========================
    Intro Section
  ============================-->
  <section id="intro">
    <div class="intro-container wow fadeIn">
      <h1 class="mb-4 pb-0">The 36<sup><small>th</small></sup> Conference<br><span> on Computational Linguistics and Speech Processing </span> <br>(ROCLING 2024)</h1>
      <p class="mb-4 pb-0">November 4<sup>th</sup>-5<sup>th</sup>, Academia Sinica, Taipei City, Taiwan</p>
<!--
      <a href="https://youtu.be/7f1dL0jxSs4" class="venobox play-btn mb-4" data-vbtype="video"
        data-autoplay="true"></a>
      <a href="https://aclanthology.org/events/rocling-2023/" target="_blank" class="about-btn scrollto">Click here to see proceedings</a>
-->
      <div id="news" class="alert alert-light fade show" role="alert">
<!--
        <i class="fa fa-bullhorn"></i> 2023/11/10 The presentation slides and video of some sessions have been released for all participants, please the program section.<br> 
        <i class="fa fa-bullhorn"></i> 2023/11/06 <a href="https://aclanthology.org/events/rocling-2023/" target="_blank">ROCLIGN 2023 proceedings</a> are now available on ACL Anthology.<br> 
        <i class="fa fa-bullhorn"></i> 2023/10/21 Thank you to all participants. The ROCLING 2024 conference has a large number of papers, and all of them have first authors from five different countries. Let's meet next year!<br> 
        <i class="fa fa-bullhorn"></i> 2023/10/20 Welcome to ROCLING 2024!!<br> 
        <i class="fa fa-bullhorn"></i> 2023/10/06 The late registration deadline has been extended to October 10 (Tue), 2023.<br> 
        <i class="fa fa-bullhorn"></i> 2023/09/26 The conference program has been announced.<br>
        <i class="fa fa-bullhorn"></i> 2023/09/09 Congratulations on these acceptance of papers for contribution of the ROCLING 2024! Please read the <a href="#camera-ready"><b>submission guidelines</b></a> to finish your camera-ready paper submission.<br>
        <i class="fa fa-bullhorn"></i> 2023/09/09 Accepted papers for Main Conference is posted. Please see the <a href="#accepted-papers"><b>accepted paper list</b></a>.<br>
        <i class="fa fa-bullhorn"></i> 2023/09/08 The notification of acceptance will be sent as soon as possible. Since, the review process requires a lot of time on the part of the reviewers.<br>
        <i class="fa fa-bullhorn"></i> 2023/09/01 Register today for ROLLING 2023. We look forward to seeing all of you there.<br>
        <i class="fa fa-bullhorn"></i> 2023/08/17 The final submission deadline has been extended to August 25 (Fri), 2023.<br> 
        <i class="fa fa-bullhorn"></i> <del>2023/08/10 The submission deadline has been extended to August 18 (Fri), 2023.</del><br> 
        <i class="fa fa-bullhorn"></i> 2023/08/01 The registration system is now open!<br> 
-->
        <i class="fa fa-bullhorn"></i> 2023/08/11 The submission due is further extended to September 7<br> 
        <i class="fa fa-bullhorn"></i> <del>2023/08/11 The submission due is extended to August 31</del><br> 
        <i class="fa fa-bullhorn"></i> 2023/08/01 The submission system is now open!<br> 
        <i class="fa fa-bullhorn"></i> 2024/06/15 The ROCLING 2024 offical website is now open! 
      </div>
    </div>
  </section>

  <main id="main">

    <!--==========================
      About Section
    ============================-->
    <section id="about">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-10">
            <h2>About the Conference</h2>
			<p>The 36th Conference on Computational Linguistics and Speech Processing (ROCLING 2024) is the annual conference of the Association for Computational Linguistics and Chinese Language Processing (ACLCLP). 
It is a renowned international conference in the fields of natural language processing and speech processing, held annually. With a long history of thirty-five sessions, its research themes encompass various issues and related applications in natural language and speech signal processing. 
This year's conference will be hosted by Academia Sinica. 
The conference will feature keynote speeches by invited experts and scholars, as well as contributions from academia and industry, which will undergo a rigorous peer review process. 
High-quality papers will be presented, and there will also be a presentation of research project results funded by the National Science Council. 
In recent years, large language models (LLMs) have realized the capabilities of fluent dialogue, responsive interactions, and question comprehension in artificial intelligence, garnering widespread public interest and attention in the development of natural language and speech processing. 
This year's ROCLING conference anticipates that experts, scholars, and technical personnel interested in natural language and speech will explore the depth and breadth of research and applications in computational linguistics.</p>
          </div>
        </div>
        <div class="row justify-content-center">
          <div class="col-lg-6">
            <h3>Where</h3>
            <p>Academia Sinica, Taipei City, Taiwan</p>
          </div>
          <div class="col-lg-4">
            <h3>When</h3>
            <p>November 4 (Monday) to 5 (Tuesday), 2024</p>
          </div>
        </div>
      </div>
    </section>

    <!--==========================
      Important Dates Section
    ============================-->
    <section id="dates"  class="wow fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Important Dates</h2>
          <p></p>
        </div>
        <h3 class="sub-heading"></h3>
        <div class="row justify-content-center">
          <div class="col-lg-2"></div>
          <div class="col-lg-7">
            <div class="card">
              <div class="card-body">
                <!--<div class="row text-muted">-->
				<div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> Paper Submission Due</div>
                  <div class="col-6 date"><del>August 31, 2024</del> September 7, 2024 (Extended)</div>
                </div>
                <div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> Notification of Acceptance</div>
                  <div class="col-6 date">September 24, 2024</div>
                </div>
               <div class="row">
                  <div class="col-6 "><i class="fa fa-check"></i> Early Registration Ends</div>
                  <div class="col-6 date">October 11, 2024</div>
                </div>
                <div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> Camera-Ready Due</div>
                  <div class="col-6 date">October 5, 2024</div>
                </div>
                <div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> Late Registration Ends</div>
                  <div class="col-6 date">October 27, 2024</div>
                </div>
                <div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> On-Site Registration</div>
                  <div class="col-6 date">November 4-5, 2024</div>
                </div>
                <div class="row">
                  <div class="col-6"><i class="fa fa-check"></i> Conference Date</div>
                  <div class="col-6 date">November 4-5, 2024</div>
                </div>
                <hr>
                <div class="text-center text-muted">
                  <p>All deadlines are 11.59 pm UTC/GMT +08:00 (Asia/Taipei)</p>
                  <div class="d-none">
                    <div class="display-date">
                      <span>NOW</span><br>
                      <span id="day">day</span>,
                      <span id="daynum">00</span>
                      <span id="month">month</span>
                      <span id="year">0000</span>
                    </div>
                    <div class="display-time"></div>
                  </div>

                </div>
              </div>
            </div>
          </div>
          <div class="col-lg-2"></div>
        </div>
      </div>
    </section>

    <!--==========================
    Carousel
    ============================-->
<!--
    <section id="photo" class="wow fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Photo</h2>
        </div>
        <div id="carouselExampleControls" class="carousel slide" data-bs-ride="carousel">
          <div class="carousel-inner" id="carouselInner">
            <div class="carousel-item active">
              <img src="img/photo/2T1A0583.jpg" class="d-block w-100">
            </div>
          </div>
          <button class="carousel-control-prev btn btn-outline-dark" type="button" data-target="#carouselExampleControls" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
          </button>
          <button class="carousel-control-next btn btn-outline-dark" type="button" data-target="#carouselExampleControls" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
          </button>
        </div>
      </div>
    </section>
-->
    <!--==========================
      Call For Paper Section
    ============================-->
    <section id="call"  class="section-with-bg fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Call for Papers</h2>
          <p></p>
        </div>
        <h3 class="sub-heading"></h3>
        <div class="row justify-content-center">
          <div class="col-lg-10">
            <p>ROCLING 2024 invites paper submissions reporting original research results and system development experiences as well as real-world applications. Each submission will be reviewed based on originality, significance, technical soundness, and relevance to the conference. Accepted papers will be presented orally or as poster presentations. 
			Both oral and poster presentations will be published in the ROCLING 2024 conference proceedings and included in the <a href="https://aclanthology.org/venues/rocling">ACL Anthology</a>. 
			A number of papers will be selected and invited for extension into journal versions and publication in a special issue of the International Journal of Computational Linguistics and Chinese Language Processing (IJCLCLP).</p>
            <h3>Page Limitation</h3>
            <p>Papers can be written and presented in either Chinese or English. Papers should be made in PDF format and submitted online through the paper submission system. 
	Submitted papers may consist of 4-8 pages of content, plus unlimited references. Upon acceptance, final versions will be given additional pages of content (up to 9 pages) so that reviewers’ comments can be taken into account.</p>
            <h3>Relevant topics</h3>
            <p>ROCLING 2024 mainly targets two scientific tracks: natural language processing and speech processing. The generative artificial intelligence topic is also welcomed.</p>
            <div class="row">
              <div class="col-lg-6">
                <h4>Natural Language Processing</h4>
                <ul>
                  <li>Cognitive/Psychological Linguistics</li>
                  <li>Discourse and Pragmatics</li>
                  <li>Dialogue System</li>
                  <li>Information Extraction</li>
                  <li>Information Retrieval</li>
                  <li>Language Generation</li>
                  <li>Machine Translation</li>
                  <li>NLP Applications</li>
                  <li>Phonology, Morphology and Word Segmentation</li>
                  <li>Question Answering</li>
                  <li>Resources and Evaluation</li>
                  <li>Semantics: Lexical, Sentence-Level, Textual Inference</li>
                  <li>Sentiment Analysis</li>
                  <li>Summarization</li>
                  <li>Syntax: Tagging, Chunking and Parsing</li>
                  <li>Others</li>
                </ul>
              </div>
              <div class="col-lg-6">
                <h4>Speech Processing</h4>
                <ul>
                  <li>Speech Perception, Production and Acquisition</li>
                  <li>Phonetics, Phonology and Prosody</li>
                  <li>Analysis of Paralinguistics in Speech and Language</li>
                  <li>Speaker and Language Identification</li>
                  <li>Analysis of Speech and Audio Signals</li>
                  <li>Speech Coding and Enhancement</li>
                  <li>Speech Synthesis and Spoken Language Generation</li>
                  <li>Speech Recognition</li>
                  <li>Spoken Dialog Systems and Analysis of Conversation</li>
                  <li>Spoken Language Processing: Retrieval, Translation, Summarization, Resources and Evaluation</li>
                  <li>Others</li>
                </ul>
              </div>
            </div>
            <h3>Online submission system</h3>
            <p>Paper submissions must use the official ROCLING 2024 style templates (Latex and Word) and <a href="files/rocling2024-templates.zip">download here</a>. Submission is electronic, using the EasyChair conference management system. The submission site is available at <a href="https://easychair.org/conferences/?conf=rocling2024" target="_blank">https://easychair.org/conferences/?conf=rocling2024</a></p>
            <p>As the reviewing will be double-blind, papers must not include authors' names and affiliations. Furthermore, self-references that reveal the author's identity must be avoided. Papers that do not conform to these requirements will be rejected without review. Papers may be accompanied by a resource (software and/or data) described in the paper, but these resources should be anonymized as well.</p>
          </div>
        </div>
      </div>
    </section>

    <!--==========================
      Accepted Papers Section
    ============================-->
<!--
    <section class="accordion" id="accepted-papers" class="wow fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Accepted Papers</h2>
          <p></p>
        </div>
        <div class="row justify-content-center">
          <div class="col-lg-10">
            <p>Congratulations on these acceptance of papers for presentation at the ROCLING 2024! We appreciate your contribution to the conference and look forward to your participation. We appreciate your contribution to the conference and look forward to your participation.</p>
            <button class="btn btn-link btn-block text-left" type="button" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne"><h4>ORAL Presentation <small>click to see more</small></h4>
            </button>
            <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accepted-papers">
              <ul>
                <li><span class="title">Construction of Message Deliver Service Dialog Systems</span> (#1)<br><span class="authors">Cheng-Hung Yeh and Chia-Hui Chang</span></li>
                <li><span class="title">Sentence-level Revision with Neural Reinforcement Learning</span> (#3)<br><span class="authors">Zhendong Du and Kenji Hashimoto</span></li>
                <li><span class="title">Multimodal Speech Training for the Hard of Hearing in Mandarine</span> (#4)<br><span class="authors">慶祥 何, 坤川 曾 and 曼菁 雷</span></li>
                <li><span class="title">Is GPT-4 a Good Islamic Expert for Answering Quran Questions?</span> (#5)<br><span class="authors">Sarah Alnefaie, Eric Atwell and Mohammad Ammar Alsalka</span></li>
                <li><span class="title">Auxiliary loss to attention head for end to end speaker diarization</span> (#6)<br><span class="authors">Yi-Ting Yang, Jiun-Ting Li and Berlin Chen</span></li>
                <li><span class="title">XFEVER: Exploring Fact Verification across Languages</span> (#7)<br><span class="authors">Yi-Chen Chang, Canasai Kruengkrai and Junichi Yamagishi</span></li>
                <li><span class="title">Enhancing Automated English Speaking Assessment for L2 Speakers with BERT and Wav2vec2.0 Fusion</span> (#8)<br><span class="authors">Wen-Hsuan Peng, Hsin-Wei Wang, Sally Chen and Berlin Chen</span></li>
                <li><span class="title">Analyzing ChatGPT's Mathematical Deficiencies: Insights and Contributions</span> (#9)<br><span class="authors">Vincent Cheng and Yu Zhang</span></li>
                <li><span class="title">Taiwanese/Mandarin Speech Recognition using OpenAI's Whisper Multilingual Speech Recognition Engine Based on Generative Pretrained Transformer Architecture</span> (#10)<br><span class="authors">Yueh-Che Hsieh and Renyuan Lyu</span></li>
                <li><span class="title">An Analysis of “X shi Y” Metaphors in Mandarin Corpora and Learning Materials</span> (#11)<br><span class="authors">Yu-Hsiang Shen and Siaw-Fong Chung</span></li>
                <li><span class="title">The Pilot Study and Model Construction for Word Segmentation in Taiwan Hakka</span> (#12)<br><span class="authors">Chiou-Shing Yeh, Huei-Ling Lai and Jyi-Shane Liu</span></li>
                <li><span class="title">Compact CNNs for End-to-End Keyword Spotting on Resource-Constrained Edge AI Devices</span> (#15)<br><span class="authors">Joseph Lin and Renyuan Lyu</span></li>
                <li><span class="title">Improving End-to-end  Taiwanese-Speech-to-Chinese-Text Translation by Semi-supervised Learning</span> (#17)<br><span class="authors">Yu-Chun Lin, Chung-Che Wang and Jyh-Shing Jang</span></li>
                <li><span class="title">Addressing  the issue of Data Imbalance in Multi-granularity Pronunciation Assessment</span> (#18)<br><span class="authors">Meng-Shin Lin, Hsin-Wei Wang, Tien-Hong Lo, Berlin Chen and Wei-Cheng Chao</span></li>
                <li><span class="title">Category Mapping for Zero-shot Text Classification</span> (#20)<br><span class="authors">Qiu-Xia Zhang, Te-Yu Chi, Te-Lun Yang, Yu-Meng Tang, Ta-Lin Chen and Jyh-Shing Jang</span></li>
                <li><span class="title">Sound Processing for Cochlear Implants: The Journey of Innovation Toward Artificial Intelligence</span> (#21)<br><span class="authors">Enoch Hsin-Ho Huang, Chao-Min Wu and Yu Tsao</span></li>
                <li><span class="title">ESC MA-SD Net: Effective Speaker Separation through Convolutional Multi-View Attention and SudoNet</span> (#22)<br><span class="authors">Che-Wei Liao, Aye Nyein Aung and Jeih-Weih Hung</span></li>
                <li><span class="title">Leveraging Dialogue Discourse Parsing in a Two-Stage Framework for Meeting Summarization</span> (#23)<br><span class="authors">Yi-Ping Huang, Tien-Hong Lo and Berlin Chen</span></li>
                <li><span class="title">Improving Low-Resource Speech Recognition through Multilingual Fine-Tuning with Language Identifiers and Self-Training</span> (#24)<br><span class="authors">Karol Nowakowski and Michal Ptaszynski</span></li>
                <li><span class="title">Story Co-telling Dialogue Generation via Reinforcement Learning and Knowledge Graph</span> (#25)<br><span class="authors">聿鎧 李 and Chia-Hui Chang</span></li>
                <li><span class="title">SCU-MESCLab at ROCLING-2023 Shared Task：Named Entity Recognition Using Multiple Classifier Model</span> (#27 MultiNER-Health)<br><span class="authors">Ruei-Cyuan Su, Tzu-En Su, Tsung-Hsien Yang and Ming-Hsiang Su</span></li>
                <li><span class="title">AaWLoss: An Artifact-aware Weighted Loss Function for Speech Enhancement</span> (#30)<br><span class="authors">En-Lun Yu, Kuan-Hsun Ho and Berlin Chen</span></li>
                <li><span class="title">A Comparative Study of Generative Pre-trained Transformer-based  Models for Chinese Slogan Generation of Crowdfunding</span> (#32)<br><span class="authors">Yu-Cheng Liang, Meng-Heng Zheng and Jheng-Long Wu</span></li>
                <li><span class="title">Application of Deep Learning Technology to Predict Changes in Sea Level</span> (#34)<br><span class="authors">Yi-Lin Hsieh and Ming-Hsiang Su</span></li>
                <li><span class="title">WordRank: A Word Ranking based Training Strategy for Abstractive Document Summarization</span> (#35)<br><span class="authors">Hsiao-Wei Chou, Pingyen Wu, Jia-Jang Tu and Kuanyu Chen</span></li>
                <li><span class="title">Overview of the ROCLING 2024 Shared Task for Chinese Multi-genre Named Entity Recognition in the Healthcare Domain</span> (#36 MultiNER-Health)<br><span class="authors">Lung-Hao Lee, Tzu-Mi Lin and Chao-Yi Chen</span></li>
                <li><span class="title">CrowNER at ROCLING 2024 MultiNER-Health Task: Enhancing NER Task with GPT Paraphrase Augmentation on Sparsely Labeled Data</span> (#37 MultiNER-Health)<br><span class="authors">Yin-Chieh Wang, Wen-Hong Wu, Feng-Yu Kuo, Han-Chun Wu, Te-Yu Chi, Te-Lun Yang, Sheh Chen and Jyh-Shing Roger Jang</span></li>
                <li><span class="title">ISLab  at  ROCLING  2023 MultiNER-Health Task:  A Three-Stage NER Model Combining  Textual Content and Tagged Semantics</span> (#40 MultiNER-Health)<br><span class="authors">Jun-Jie Wu, Yu-Cheng Liu, Tao-Hsing Chang and Fu-Yuan Hsu</span></li>
                <li><span class="title">Fine-Tuning and Evaluation of Question Generation for Slovak Language</span> (#41)<br><span class="authors">Ondrej Megela, Daniel Hladek, Matus Pleva, Ján Staš, Ming-Hsian Su and Yuan-Fu Liao</span></li>
                <li><span class="title">The Relevance Identification Between Housing Rental Texts And Legal Provisions</span> (#43)<br><span class="authors">Min-Chin Ho, Ya-Mien Cheng and Jheng-Long Wu</span></li>
                <li><span class="title">Impact of Feature Selection Algorithms on Readability Model</span> (#44)<br><span class="authors">采寧 戴, 厚強 曾 and 曜廷 宋</span></li>
                <li><span class="title">Investigating Cross-Institutional Recognition of Cancer Registration Items: A Case Study on Catastrophic Forgetting</span> (#46)<br><span class="authors">You Chen Zhang, Hong-Jie Dai and Chen-Kai Wang</span></li>
                <li><span class="title">Phonotactic Constraints on Zhangzhou Onsets</span> (#47)<br><span class="authors">Yishan Huang</span></li>
                <li><span class="title">Accelerating Hakka Speech Recognition Research and Development Using the Whisper Model</span> (#48 Hakka-ASR)<br><span class="author">Ching-Yuan Chen, Yun-Hsiang Hsu and Chenchi Chang</span></li>
                <li><span class="title">Enhancing Automatic Speech Recognition Performance Through Multi-Speaker Text-to-Speech</span> (#49 Hakka-ASR)<br><span class="author">Po-Kai Chen, Bing-Jhih Huang, Chi-Tao Chen, Hsin-Min Wang and Jia-Ching Wang</span></li>
                <li><span class="title">The DMS-ASR System for the Formosa Speech Recognition Challenge 2023</span> (#50 Hakka-ASR)<br><span class="author">Hsiu Jui Chang and Wei Yuan Chen</span></li>
                <li><span class="title">NSYSU-MITLab Speech Recognition System for Formosa Speech Recognition Challenge 2023</span> (#51 Hakka-ASR)<br><span class="author">Hong-Jie Hu and Chia-Ping Chen</span></li>
                <li><span class="title">The North System for Formosa Speech Recognition Challenge 2023</span> (#52 Hakka-ASR)<br><span class="author">Li-Wei Chen, Hung-Shin Lee and Kai-Chen Cheng</span></li>
                <li><span class="title">WhisperHakka: A Hybrid Architecture Speech Recognition System for Low-Resource Taiwanese Hakka</span> (#53 Hakka-ASR)<br><span class="author">Ming-Hsiu Chiang, Chien-Hung Lai and Hsuan-Sheng Chiu</span></li>
                <li><span class="title">The NTNU ASR System for Formosa Speech Recognition Challenge 2023</span> (#54 Hakka-ASR)<br><span class="author">Hao-Chien Lu, Chung-Chun Wang, Jhen-Ke Lin and Tien-Hong Lo</span></li>
                <li><span class="title">The Taiwan AI Labs Hakka ASR System for Formosa Speech Recognition Challenge 2023</span> (#55 Hakka-ASR)<br><span class="author">Yuan-Hsiang Lu, Chung-Yi Li and Zih-Wei Lin</span></li>
                <li><span class="title">A Preliminary Study on Hakka Speech Recognition by Using the Branchformer</span> (#56 Hakka-ASR)<br><span class="author">Jia-Jyu Su, Dong-Min Li and Chen-Yu Chiang</span></li>
                <li><span class="title">The NTNU Super Monster Team (SPMT) system for the Formosa Speech Recognition Challenge 2023 - Hakka ASR</span> (#57 Hakka-ASR)<br><span class="author">Tzu-Ting Yang, Hsin Wei Wang, Meng-Ting Tsai and Berlin Chen</span></li>
                <li><span class="title">Whisper Model Adaptation for FSR-2023 Hakka Speech Recognition Challenge</span> (#58 Hakka-ASR)<br><span class="author">Yi-Chin Huang and Ji-Qian Tsai</span></li>
              </ul>
            </div>
            
            <button class="btn btn-link btn-block text-left" type="button" data-toggle="collapse" data-target="#collapseSecond" aria-expanded="true" aria-controls="collapseSecond"><h4>POSTER Presentation <small>click to see more</small></h4>
            </button>
            <div id="collapseSecond" class="collapse" aria-labelledby="headingSencond" data-parent="#accepted-papers">
              <ul>
                <li><span class="title">KNOT-MCTS: An Effective Approach to Addressing Hallucinations in Generative Language Modeling for Question Answering</span> (#13)<br><span class="authors">Chung-Wen Wu, Guan-Tang Huang, Yue-Yang He and Berlin Chen</span></li>
                <li><span class="title">Can generative models be used to detect hate speech related to body shaming?</span> (#14)<br><span class="authors">元翔 蔡 and 瑜芸 張</span></li>
                <li><span class="title">A Novel Named Entity Recognition Model Applied to Specialized Sequence Labeling</span> (#16)<br><span class="authors">Ruei-Cyuan Su, Tzu-En Su, Ming-Hsiang Su, Matus Pleva and Daniel Hladek</span></li>
                <li><span class="title">Analysis of Chinese Irony on PTT Corpus-Using "Tested Positive" and "Hope" as the Key Words</span> (#19)<br><span class="authors">品文 王 and 曉芳 鍾</span></li>
                <li><span class="title">Evaluating Interfaced LLM Bias</span> (#26)<br><span class="authors">Kai-Ching Yeh, Jou-An Chi and Da-Chen Lian</span></li>
                <li><span class="title">YNU-HPCC at ROCLING 2024 MultiNER-Health Task: A transformer-based approach for Chinese healthcare NER</span> (#28 MultiNER-Health)<br><span class="authors">Chonglin Pang, You Zhang and Xiaobing Zhou</span></li>
                <li><span class="title">YNU-ISE-ZXW at ROCLING 2024 MultiNER-Health Task: A Transformer-based Model with LoRA for Chinese Healthcare Named Entity Recognition</span> (#29 MultiNER-Health)<br><span class="authors"></span>Xingwei Zhang, Jin Wang and Xuejie Zhang</li>
                <li><span class="title">Analyzing Bid-Rigging Related Judicial Cases of Government Procurement Law Using Text Mining Techniques</span> (#31)<br><span class="authors">Pei-Zhen Chen, Hsin-Yun Hsu and Jheng-Long Wu</span></li>
                <li><span class="title">Fine-Grained Argument Understanding with BERT Ensemble Techniques:  A Deep Dive into Financial Sentiment Analysis</span> (#33)<br><span class="authors">Sy Eugene L., Tzu-Cheng Peng, Shih-Hsuan Huang, Hen-You Lin and Yung-Chun Chang</span></li>
                <li><span class="title">Wangxuelin at ROCLING 2024 MultiNER-Health Task: Intelligent Capture of Chinese Medical Named Entities by LLM: Instruct-Tuning via Entity Extraction-Style Prompts</span> (#38 MultiNER-Health)<br><span class="authors">Xuelin Wang and Qihao Yang</span></li>
                <li><span class="title">Lexical Complexity Prediction using Word Embeddings</span> (#39)<br><span class="authors">Cheng-Zen Yang, Jin-Jian Li and Shu-Chang Lin</span></li>
                <li><span class="title">Solving Linguistic Olympiad Problems with Tree-of-Thought Prompting</span> (#45)<br><span class="authors">Zheng-Lin Lin, Chiao-Han Yen, Jia-Cheng Xu, Deborah Watty and Shu-Kai Hsieh</span></li>
              </ul>
            </div>            
          </div>
        </div>
       
      </div>
    </section>
-->
    <!--==========================
      Camera-Ready Paper Section
    ============================-->
<!--
    <section id="camera-ready"  class="section-with-bg fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Camera-Ready Paper Submission Guidelines</h2>
          <p></p>
        </div>
        <h3 class="sub-heading"></h3>
        <div class="row justify-content-center">
          <div class="col-lg-10">
            <p>To ensure a smooth and successful publication process, please adhere to the following camera-ready paper submission guidelines.</p>
            <h4>Important Dates</h4>
            <ul>
              <li>Camera-ready paper submission deadline: September 15 (Fri), 2023</li>
              <li>Registration deadline: September 15 (Fri), 2023</li>
            </ul>
            <h4>Paper Length</h4>
            <p>Your camera-ready paper should not exceed 9 pages (plus unlimited references) in the PDF format.</p>
            <h4>Paper Format</h4>
            <p>The template is compatible with popular document preparation systems such as LaTeX and Microsoft Word. Please strictly follow the formatting guidelines provided in the <a href="assets/rocling2023-templates.zip">final template</a></p>
            <h4>File Format</h4>
            <p>Submit your camera-ready paper in PDF format.</p>
            <h4>Paper Content</h4>
            <p>The first page of the camera-ready version of the accepted paper should bear the items of paper title, author name, affiliation, and email address.</p>
            <p>All these items should be properly centered on the top, followed by a concise abstract of the paper. In addition, Chinese manuscript must to write English title, abstract, and keywords.</p>
            <h4>Author Information</h4>
            <p>Ensure that the author list in your paper is final and correct, as it will be used for conference materials and proceedings. Changes to the author list after submission will not be allowed.</p>
            <h4>Copyright Forms</h4>
            <p>Authors must sign and upload a copyright document, granting the conference organizers the right to publish the paper in the conference proceedings. The copyright form is available for download <a href="assets/rocling2023_copyright.doc"> here</a>.</p>
            <h4>Submission Instructions</h4>
            <p>Camera-ready papers should be submitted electronically through the conference submission system, which can be accessed at <a href="https://easychair.org/conferences/?conf=rocling2023" target="_blank">https://easychair.org/conferences/?conf=rocling2023</a>. Please log in using your existing account and follow the instructions for paper submission. Each item on the forms in submission system must be written in English.</p>
            <h4>Plagiarism Check</h4>
            <p>Camera-ready paper must to do plagiarism detection by authorself. Ensure that your submission is original and properly cited.</p>
            <h4>Registration</h4>
            <p>At least one author must pay the regular registration fee for each publication paper (including shared tasks). More registration information, please see at <a href="#buy-registrations">here</a></p>
          </div>
        </div>
      </div>
    </section>
-->
    <!--==========================
      Schedule Section
    ============================-->
    <section id="schedule" class="wow fadeInUp">
      <div class="container wow fadeInUp">
        <div class="section-header">
          <h2>Programs</h2>
          <p>Humanities and Social Sciences Building (HSSB) of Academia Sinica</p>
        </div>
        <h3 class="sub-heading"></h3>
        <!-- Schdule Day 1 -->
        <div class="row">
          <ul class="nav nav-tabs" role="tablist">
            <li class="nav-item">
              <h5><a class="nav-link active" href="#day-1" role="tab" data-toggle="tab">Day 1 (Monday), November 4, 2024</a></h5>
            </li>
          </ul>
        </div>
        <div class="tab-content row justify-content-center">
          <div role="tabpanel" class="col-11 tab-pane fade show active" id="day-1">
            <div class="row schedule-item">
              <div class="col-md-2"><time>08:30 - 09:00</time></div>
              <div class="col-md-10">
                <h4>Registration <span>Location: 3rd floor of HSSB</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>09:00 - 09:20</time></div>
              <div class="col-md-10">
                <h4>Opening Ceremony <span>Location: 1st Conference Room</span></h4>
                <p></p>
              </div>
            </div>
            <div class="row schedule-item">
              <div class="col-md-2"><time>09:20 - 10:20</time></div>
              <div class="col-md-10">
                <h4>Keynote Session I<span> Location: 1st Conference Room</span></h4>
                <h7>Speaker: <a href="https://blender.cs.illinois.edu/hengji.html">Heng Ji</a>, University of Illinois Urbana-Champaign</h7>
<!--
                <h7 class="chair">Chair: Professor Hen-Hsen Huang</h7>-->
                <div class="mt-2">
                  <div class="speaker">
                    <img src="img/keynote/ji.png" alt="Heng Ji">
                  </div>
                  <p>Title: Making Large Language Model’s Knowledge More Accurate, Organized, Up-to-date and Fair<a href="#speakers-1"><i class="fa fa-info-circle" aria-hidden="true"></i></a></p>
                  <h7>Speaker: Doctor Heng Ji</h7>
                  <br>
                  <!--
                  <h7 class="file_link">
                    <i class="fa fa-file-pdf-o"></i>
                    <a href="assets/ROCLING2023_Nancy_F._Chen.pdf">Slide</a>
                  </h7>
                  <br>
                  <h7 class="file_link">
                    <i class="fa fa-youtube"></i>
                    <a href="https://youtu.be/zvyiduH-a9c" target="_blank">Video</a>
                  </h7>
                  -->
                </div>
              </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>10:20 - 10:40</time></div>
              <div class="col-md-10">
                <h4>Coffee Break <span>Location: outside the 1st Conference Room</span></h4>
              </div>
            </div>
            <div class="row schedule-item">
              <div class="col-md-2"><time>10:40 - 12:00</time></div>
              <div class="col-md-10">
                <h4>Oral Session I (Thesis Award Winners' Presentation)<span>Location: 1st Confernece Room</span></h4>
              </div>
            </div>
	   <div class="row schedule-item">
              <div class="col-md-2"><time>12:00 - 13:00</time></div>
              <div class="col-md-10">
                <h4>Lunch<span>Location: outside the 1st Conference Room</span></h4>
              </div>
            </div>
			<div class="row schedule-item">
              <div class="col-md-2"><time>13:00 - 14:00</time></div>
              <div class="col-md-10">
                <h4>ACLCLP Assembly<span>Location: 1st Conference Room</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
                <div class="col-md-2"><time>14:00 - 15:30</time></div>
                <div class="col-md-10">
                    <h4>Oral Session II<span>Location: 1st Conference Room</span></h4>
                    <hr>
                    <h4>Oral Session III<span>Location: 2nd Conference Room</span></h4>
                </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>15:30 - 15:50</time></div>
              <div class="col-md-10">
                <h4>Coffee Break <span>Location: outside the 1st Conference Room</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
                <div class="col-md-2"><time>15:50 - 17:20</time></div>
                <div class="col-md-10">
                    <h4>Tutorial<span>Location: 1st Conference Room</span></h4>
                </div>
            </div>
          </div>
          <!-- End Schdule Day 1 -->
        </div>

        <br><br><br><br>
        
        <!-- Schdule Day 2 -->
        <div class="row">
          <ul class="nav nav-tabs" role="tablist">
            <li class="nav-item">
              <h5><a class="nav-link active" href="#day-2" role="tab" data-toggle="tab">Day 2 (Tuesday), November 5, 2024</a></h5>
            </li>
          </ul>
        </div>
        <div class="tab-content row justify-content-center">
          <div role="tabpanel" class="col-11 tab-pane fade show active" id="day-1">
            <div class="row schedule-item">
              <div class="col-md-2"><time>09:00 - 10:00</time></div>
              <div class="col-md-10">
                <h4>Keynote Session II<span> Location: 1st Conference Room</span></h4>
                <!--                <h7>Speaker: <a href="https://www.cs.cmu.edu/~hovy/">Eduard Hovy</a>, Carnegie Mellon University</h7>   -->
<!--                <h7 class="chair">Chair: Professor Hung-Yi Lee</h7>
                <div class="mt-2">
                  <div class="speaker">
                    <img src="img/keynote/Peng-Jen.jpg" alt="Peng-Jen Chen">
                  </div>
                  <p>Title: Building Speech-to-Speech Translation System for English-Hokkien <a href="#speakers-2"><i class="fa fa-info-circle" aria-hidden="true"></i></a></p>
                  <h7>Speaker: Doctor Peng-Jen Chen</h7>
                </div>
-->
              </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>10:00 - 10:20</time></div>
              <div class="col-md-10">
                <h4>Coffee Break <span>Location: outside the 1st Conference Room</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
                <div class="col-md-2"><time>10:20 - 11:20</time></div>
                <div class="col-md-10">
                    <h4>TAIDE Session<span>Location: 1st Conference Room</span></h4>
                </div>
            </div>
            <div class="row schedule-item">
              <div class="col-md-2"><time>11:20 - 12:40</time></div>
              <div class="col-md-10">
                <h4>Oral Session IV<span>Location: 1st Conference Room</span></h4>
                <hr>
                <h4>Oral Session V<span>Location: 2nd Conference Room</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>12:40 - 13:30</time></div>
              <div class="col-md-10">
                <h4>Lunch<span>Location: outside the 1st Conference Room</span></h4>
              </div>
            </div>

            <div class="row schedule-item">
              <div class="col-md-2"><time>13:30 - 15:30</time></div>
              <div class="col-md-10">
                <h4>Poster Session<span>Location: outside the 2nd Conference Room</span></h4>
<!--
                <button type="button" class="btn btn-link papers" data-toggle="modal" data-target="#modal-session-poster">Papers</button>
-->
              </div>
            </div>
            <div class="row schedule-item">
              <div class="col-md-2"><time>15:30 - 17:00</time></div>
              <div class="col-md-10">
                <h4>Oral Session VI (Best Paper Award)<span>Location: 1st Conference Room</span></h4>
<!--                <h7 class="chair">Chair: Professor Siaw-Fong Chung</h7>
                <p>Topic: Speech Recognition</p>
                <button type="button" class="btn btn-link papers" data-toggle="modal" data-target="#modal-session-5">Papers</button>
                <hr>
                <h4>AI Tutorial 1 <span>Location: R0101</span></h4>
                <div class="mt-2">
                  <div class="speaker ml-2">
                    <img src="img/speakers/Cheng-Te_Li.jpg" alt="Cheng-Te Li">
                  </div>
                  <p>Topic: Demystifying Graph Neural Networks: Essentials, Applications, and Trends <a href="#ai1"><i class="fa fa-info-circle" aria-hidden="true"></i></a></p>
                  <h7>Speaker: Professor Cheng-Te Li</h7>
                  <br>
                </div>
-->
              </div>
            </div>
            <div class="row schedule-item">
              <div class="col-md-2"><time>17:00 - 17:20</time></div>
              <div class="col-md-10">
                <h4>Closing Ceremony <span>Location: 1st Conference Room</span></h4>

              </div>
            </div>
          </div>
          <!-- End Schdule Day 2 -->
        </div>

        <br><br><br><br>

        
        <!-- Schdule papers -->
        <div class="row justify-content-center">
          <div class="col-lg-10 detailed-programs">
            <!-- Modal Session 1 -->
            <div class="modal fade" id="modal-session-1" tabindex="-1" aria-labelledby="modal-session-1Label" aria-hidden="true">
              <div class="modal-dialog modal-xl modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-1Label">Oral Session 1: Best Paper Award Candidates</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Auxiliary Loss to Attention Head for End to End Speaker Diarization</span> (#6)<br><span class="author">Yi-Ting Yang, Jiun-Ting Li and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">XFEVER: Exploring Fact Verification across Languages</span> (#7)<br><span class="author">Yi-Chen Chang, Canasai Kruengkrai and Junichi Yamagishi</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Improving End-to-End Taiwanese-Speech-to-Chinese-Text Translation by Semi-Supervised Learning</span> (#17)<br><span class="author">Yu-Chun Lin, Chung-Che Wang and Jyh-Shing Jang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Improving Low-Resource Speech Recognition through Multilingual Fine-Tuning with Language Identifiers and Self-Training</span> (#24)<br><span class="author">Karol Nowakowski and Michal Ptaszynski</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Story Co-Telling Dialogue Generation via Reinforcement Learning and Knowledge Graph</span> (#25)<br><span class="author">Yu-Kai Lee and Chia-Hui Chang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">WordRank: A Word Ranking based Training Strategy for Abstractive Document Summarization</span> (#35)<br><span class="author">Hsiao-Wei Chou, Ping-Yen Wu, Jia-Jang Tu and Kuanyu Chen</span></li>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session 2 -->
            <div class="modal fade" id="modal-session-2" tabindex="-1" aria-labelledby="modal-session-2Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-2Label">Oral Session 2: NLP Applications</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Sentence-Level Revision with Neural Reinforcement Learning</span> (#3)<br><span class="author">Zhendong Du and Kenji Hashimoto</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Is GPT-4 a Good Islamic Expert for Answering Quran Questions?</span> (#5)<br><span class="author">Sarah Alnefaie, Eric Atwell and Mohammad Ammar Alsalka</span></li>
                      <br>
                      <li class="text-muted"><span class="title">An Analysis of “X shi Y” Metaphors in Mandarin Corpora and Learning Materials</span> (#11)<br><span class="author">Yu-Hsiang Shen and Siaw-Fong Chung</span></li>
                      <br>
                      <li class="text-muted"><span class="title">A Comparative Study of Generative Pre-Trained Transformer-Based  Models for Chinese Slogan Generation of Crowdfunding</span> (#32)<br><span class="author">Yu-Cheng Liang, Meng-Heng Zheng and Jheng-Long Wu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Impact of Feature Selection Algorithms on Readability Model</span> (#44)<br><span class="author">Tsai-Ning Tai, Hou-Chiang Tseng and Yao-Ting Sung</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session 3 -->
            <div class="modal fade" id="modal-session-3" tabindex="-1" aria-labelledby="modal-session-3Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-3Label">Oral Session 3: Thesis Award Winners Presentation</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">持續學習閘門調適器應用於雙語神經編解碼器語音合成</span><br><span class="author">楊立任</span></li>
                      <br>
                      <li class="text-muted"><span class="title">協同式對比學習於假設領域適應</span><br><span class="author">葉宜萍</span></li>
                      <br>
                      <li class="text-muted"><span class="title">外掛式語言模型：利用一個簡單的迴歸模型控制文本生成</span><br><span class="author">楊奈其</span></li>
                      <br>
                      <li class="text-muted"><span class="title">利用學習語句表達改進中文斷詞對於不同標準的適應性</span><br><span class="author">林峻毅</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session 4 -->
            <div class="modal fade" id="modal-session-4" tabindex="-1" aria-labelledby="modal-session-4Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-4Label">Oral Session 4: Speech Applications</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Construction of Message Deliver Service Dialog Systems</span> (#1)<br><span class="author">Cheng-Hung Yeh and Chia-Hui Chang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Enhancing Automated English Speaking Assessment for L2 Speakers with BERT and Wav2vec2.0 Fusion</span> (#8)<br><span class="author">Wen-Hsuan Peng, Hsin-Wei Wang, Sally Chen and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The Pilot Study and Model Construction for Word Segmentation in Taiwan Hakka</span> (#12)<br><span class="author">Chiou-Shing Yeh, Huei-Ling Lai and Jyi-Shane Liu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Addressing the Issue of Data Imbalance in Multi-Granularity Pronunciation Assessment</span> (#18)<br><span class="author">Meng-Shin Lin, Hsin-Wei Wang, Tien-Hong Lo, Berlin Chen and Wei-Cheng Chao</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Application of Deep Learning Technology to Predict Changes in Sea Level</span> (#34)<br><span class="author">Yi-Lin Hsieh and Ming-Hsiang Su</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Fine-Tuning and Evaluation of Question Generation for Slovak Language</span> (#41)<br><span class="author">Ondrej Megela, Daniel Hladek, Matus Pleva, Ján Staš, Ming-Hsiang Su and Yuan-Fu Liao</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session 5 -->
            <div class="modal fade" id="modal-session-5" tabindex="-1" aria-labelledby="modal-session-5Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-5Label">Oral Session 5: Speech Recognition</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Multimodal Speech Training for the Hard of Hearing in Mandarine</span> (#4)<br><span class="author">Ching-Hsiang Ho, Kun-Chuan Tseng and Men-Ching Lei</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Taiwanese/Mandarin Speech Recognition using OpenAI's Whisper Multilingual Speech Recognition Engine Based on Generative Pretrained Transformer Architecture</span> (#10)<br><span class="author">Yueh-Che Hsieh, Renyuan Lyu and Keming Lyu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">ESC MA-SD Net: Effective Speaker Separation through Convolutional Multi-View Attention and SudoNet</span> (#22)<br><span class="author">Che-Wei Liao, Aye Nyein Aung and Jeih-Weih Hung</span></li>
                      <br>
                      <li class="text-muted"><span class="title">AaWLoss: An Artifact-Aware Weighted Loss Function for Speech Enhancement</span> (#30)<br><span class="author">En-Lun Yu, Kuan-Hsun Ho and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Investigating Cross-Institutional Recognition of  Cancer Registration Items: A Case Study on Catastrophic Forgetting</span> (#46)<br><span class="author">You Chen Zhang, Chen-Kai Wang, Ming-Ju Tsai and Hong-Jie Dai</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Phonotactic Constraints on Zhangzhou Onsets</span> (#47)<br><span class="author">Yishan Huang</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session 6 -->
            <div class="modal fade" id="modal-session-6" tabindex="-1" aria-labelledby="modal-session-6Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-6Label">Oral Session 6: Information Retrieval

</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Analyzing ChatGPT's Mathematical Deficiencies: Insights and Contributions</span> (#9)<br><span class="author">Vincent Cheng and Yu Zhang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Compact CNNs for End-to-End Keyword Spotting on Resource-Constrained Edge AI Devices</span> (#15)<br><span class="author">Joseph Lin and Renyuan Lyu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Category Mapping for Zero-Shot Text Classification</span> (#20)<br><span class="author">Qiu-Xia Zhang, Te-Yu Chi, Te-Lun Yang, Yu-Meng Tang, Ta-Lin Chen and Jyh-Shing Jang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Sound Processing for Cochlear Implants: The Journey of Innovation Toward Artificial Intelligence</span> (#21)<br><span class="author">Enoch Hsin-Ho Huang, Chao-Min Wu and Yu Tsao</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Leveraging Dialogue Discourse Parsing in a Two-Stage Framework for Meeting Summarization</span> (#23)<br><span class="author">Yi-Ping Huang, Tien-Hong Lo and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The Relevance Identification Between Housing Rental Texts And Legal Provisions</span> (#43)<br><span class="author">Min-Chin Ho, Ya-Mien Cheng and Jheng-Long Wu</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session shared task 1 -->
            <div class="modal fade" id="modal-session-st1" tabindex="-1" aria-labelledby="modal-session-st1Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-st1Label">Oral Session (Shared Task 1): MultiNER-Health</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">SCU-MESCLab at ROCLING-2023 Shared Task：Named Entity Recognition Using Multiple Classifier Model</span> (#27 MultiNER-Health)<br><span class="author">Tzu-En Su, Ruei-Cyuan Su, Tsung-Hsien Yang and Ming-Hsiang Su</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Overview of the ROCLING 2024 Shared Task for Chinese Multi-Genre Named Entity Recognition in the Healthcare Domain</span> (#36 MultiNER-Health)<br><span class="author">Lung-Hao Lee, Tzu-Mi Lin and Chao-Yi Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">CrowNER at ROCLING 2024 MultiNER-Health Task: Enhancing NER Task with GPT Paraphrase Augmentation on Sparsely Labeled Data</span> (#37 MultiNER-Health)<br><span class="author">Yin-Chieh Wang, Wen-Hong Wu, Feng-Yu Kuo, Han-Chun Wu, Te-Yu Chi, Te-Lun Yang, Sheh Chen and Jyh-Shing Roger Jang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">ISLab at ROCLING 2024 MultiNER-Health Task: A Three-Stage NER Model Combining Textual Content and Tagged Semantics</span> (#40 MultiNER-Health)<br><span class="author">Jun-Jie Wu, Tao-Hsing Chang and Fu-Yuan Hsu</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session shared task 2 -->
            <div class="modal fade" id="modal-session-st2" tabindex="-1" aria-labelledby="modal-session-st2Label" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-st2Label">Oral Session (Shared Task 2): Hakka ASR </h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">Accelerating Hakka Speech Recognition Research and Development Using the Whisper Model</span> (#48 Hakka-ASR)<br><span class="author">Ching-Yuan Chen, Yun-Hsiang Hsu and Chenchi Chang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Enhancing Automatic Speech Recognition Performance Through Multi-Speaker Text-to-Speech</span> (#49 Hakka-ASR)<br><span class="author">Po-Kai Chen, Bing-Jhih Huang, Chi-Tao Chen, Hsin-Min Wang and Jia-Ching Wang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The DMS-ASR System for the Formosa Speech Recognition Challenge 2023</span> (#50 Hakka-ASR)<br><span class="author">Hsiu Jui Chang and Wei Yuan Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">NSYSU-MITLab Speech Recognition System for Formosa Speech Recognition Challenge 2023</span> (#51 Hakka-ASR)<br><span class="author">Hong-Jie Hu and Chia-Ping Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The North System for Formosa Speech Recognition Challenge 2023</span> (#52 Hakka-ASR)<br><span class="author">Li-Wei Chen, Hung-Shin Lee and Kai-Chen Cheng</span></li>
                      <br>
                      <li class="text-muted"><span class="title">WhisperHakka: A Hybrid Architecture Speech Recognition System for Low-Resource Taiwanese Hakka</span> (#53 Hakka-ASR)<br><span class="author">Ming-Hsiu Chiang, Chien-Hung Lai and Hsuan-Sheng Chiu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The NTNU ASR System for Formosa Speech Recognition Challenge 2023</span> (#54 Hakka-ASR)<br><span class="author">Hao-Chien Lu, Chung-Chun Wang, Jhen-Ke Lin and Tien-Hong Lo</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The Taiwan AI Labs Hakka ASR System for Formosa Speech Recognition Challenge 2023</span> (#55 Hakka-ASR)<br><span class="author">Yuan-Hsiang Lu, Chung-Yi Li and Zih-Wei Lin</span></li>
                      <br>
                      <li class="text-muted"><span class="title">A Preliminary Study on Hakka Speech Recognition by Using the Branchformer</span> (#56 Hakka-ASR)<br><span class="author">Jia-Jyu Su, Dong-Min Li and Chen-Yu Chiang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">The NTNU Super Monster Team (SPMT) system for the Formosa Speech Recognition Challenge 2023 - Hakka ASR</span> (#57 Hakka-ASR)<br><span class="author">Tzu-Ting Yang, Hsin Wei Wang, Meng-Ting Tsai and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Whisper Model Adaptation for FSR-2023 Hakka Speech Recognition Challenge</span> (#58 Hakka-ASR)<br><span class="author">Yi-Chin Huang and Ji-Qian Tsai</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Modal Session poster -->
            <div class="modal fade" id="modal-session-poster" tabindex="-1" aria-labelledby="modal-session-posterLabel" aria-hidden="true">
              <div class="modal-dialog modal-lg modal-dialog-centered modal-dialog-scrollable">
                <div class="modal-content">
                  <div class="modal-header">
                    <h5 class="modal-title" id="modal-session-posterLabel">Poster Session</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <ul>
                      <li class="text-muted"><span class="title">KNOT-MCTS: An Effective Approach to Addressing Hallucinations in Generative Language Modeling for Question Answering</span> (#13)<br><span class="author">Chung-Wen Wu, Guan-Tang Huang, Yue-Yang He and Berlin Chen</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Can Generative Models be used to Detect Hate Speech related to Body Shaming?</span> (#14)<br><span class="author">Yuan-Shiang Tsai and Yu-Yun Chang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">A Novel Named Entity Recognition Model Applied to Specialized Sequence Labeling</span> (#16)<br><span class="author">Ruei-Cyuan Su, Tzu-En Su, Ming-Hsiang Su, Matus Pleva and Daniel Hladek</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Analysis of Chinese Irony on PTT Corpus-Using "Tested Positive" and "Hope" as the Key Words</span> (#19)<br><span class="author">品文 王 and 曉芳 鍾</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Evaluating Interfaced LLM Bias</span> (#26)<br><span class="author">Kai-Ching Yeh, Jou-An Chi, Da-Chen Lian and Shu-Kai Hsieh</span></li>
                      <br>
                      <li class="text-muted"><span class="title">YNU-HPCC at ROCLING 2024 MultiNER-Health Task: A Transformer-Based Approach for Chinese healthcare NER</span> (#28)<br><span class="author">Chonglin Pang, You Zhang and Xiaobing Zhou</span></li>
                      <br>
                      <li class="text-muted"><span class="title">YNU-ISE-ZXW at ROCLING 2024 MultiNER-Health Task: A Transformer-Based Model with LoRA for Chinese Healthcare Named Entity Recognition</span> (#29)<br><span class="author">Xingwei Zhang, Jin Wang and Xuejie Zhang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Analyzing Bid-Rigging Related Judicial Cases of Government Procurement Law Using Text Mining Techniques</span> (#31)<br><span class="author">Pei-Zhen Chen, Hsin-Yun Hsu and Jheng-Long Wu</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Fine-Grained Argument Understanding with BERT Ensemble Techniques: A Deep Dive into Financial Sentiment Analysis</span> (#33)<br><span class="author">Eugene Sy, Tzu-Cheng Peng, Shih-Hsuan Huang, Heng-Yu Lin and Yung-Chun Chang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">LingX at ROCLING 2024 MultiNER-Health Task: Intelligent Capture of Chinese Medical Named Entities by LLMs</span> (#38)<br><span class="author">Xuelin Wang and Qihao Yang</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Lexical Complexity Prediction using Word Embeddings</span> (#39)<br><span class="author">Cheng-Zen Yang, Jin-Jian Li and Shu-Chang Lin</span></li>
                      <br>
                      <li class="text-muted"><span class="title">Solving Linguistic Olympiad Problems with Tree-of-Thought Prompting</span> (#45)<br><span class="author">Zheng-Lin Lin, Chiao-Han Yen, Jia-Cheng Xu, Deborah Watty and Shu-Kai Hsieh</span></li>
                      <br>
                    </ul>
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>

        <br><br><br><br>

        <!-- Presentation Guidelines  -->
        <div id="presentationguidelines" class="row justify-content-center">
          <div class="col-lg-10">
            <h3><b>Presentation Guidelines</b></h3>
            <h4>For Oral Presentations:</h4>
            <ul>
              <!--<li>For oral presentations, we recommend downloading the ROCLING 2024 <a href="https://rocling2023.github.io/assets/rocling2023-slider-template.pptx">slider templates</a>.</li>
-->
              <li>Presentations may be conducted in either English or Chinese.</li>
              <li>Each presentation will be allocated 20 minutes for the presentation itself, included a 4-minute session for questions and answers, and an additional 1-minute break for a change of speakers.</li>
              <li>Presenters are kindly requested to introduce themselves to the session chairs before the commencement of their oral session.</li>
              <li>Each room will be equipped with:
                <ul>
                  <li>A laptop computer (Windows OS), which can load PPT and PDF</li>
                  <li>A projector</li>
                  <li>A shared Internet connection</li>
                  <li>an audio system</li>
                  <li>The display connectors for the screen are both HDMI and VGA.</li>
                </ul>
              </li>
              <li>Presenters who want to use their laptop for their presentation must bring their adapter to connect to the HDMI/VGA cable and any audio connectors if they have a non-standard audio-out port.</li>
              <li>Before the session, presenters should inform the session chair and test that their computer and adapter work with the projector in the room.</li>
              <li>A wireless internet connection will be available in the presentation rooms.</li>
            </ul>
            <h4>For Poster Presentations:</h4>
            <ul>
              <li>Posters are in A1 size (59.4 cm wide x 84.1 cm high, or 23.4 inches x 33.1 inches).</li>
              <li>Presenters are advised to mount their posters before the start of the session and dismount them after the end of the session.</li>
              <li>Materials to fix the posters will be available on-site.</li>
            </ul>
<!--
            <h4>Pre-recorded Video Instructions (Expats Only):</h4>
            <p></p>
            <ul>
              <li>In exceptional circumstances (e.g., when international speakers (foreign business travelers) cannot present live), pre-recorded presentations for oral or poster may be permitted and played during the conference.</li>
              <li>At least 15 minutes and at most 20 minutes. Within that interval, choose a duration you feel will best engage your audience. These include having a video of the presenter in the corner of the slides.</li>
              <li>The maximum volume of video is 200MB.</li>
              <li>The file format of video is *.mp4.</li>
              <li>We recommended a video resolution of at least 720 pixels and an aspect ratio of 16:9.</li>
              <li>Please note that final specifications of the pre-recorded video will be checked, non-compliant video may be requested to be re-recorded.</li>
              <li>Please sent the download link (e.g. Google Drive or Dropbox) of the pre-recorded video to the official email (rocling2023@gmail.com) by October 15. In case of poster sessions, the poster file must also be sent in the same time.</li>
            </ul>
-->
          </div>
        </div>
      </div>
    </section>

    <!--==========================
      Speakers Section
    ============================-->
<!--
    <section id="speakers" class="section-with-bg fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Keynote Speakers</h2>
        </div>
        <h3 id="speakers-1" class="text-muted">Natural Language Processing</h3>
        <div class="row">
          <div class="col-8 col-sm-5 col-md-4 col-lg-3">
            <div class="speaker">
              <img src="img/keynote/NancyFChen.png" alt="Speaker Nancy F. Chen" class="img-fluid">
              <div class="details">
                <h3><a href="https://www.a-star.edu.sg/cfar/about-cfar/our-team/dr-nancy-f-chen" target="_blank">Nancy F. Chen</a></h3>
                <p>A*STAR</p>
                <div class="social">
                  <a href="https://www.a-star.edu.sg/cfar/about-cfar/our-team/dr-nancy-f-chen" target="_blank"><i class="fa fa-info-circle"></i></a>
                </div>
              </div>
            </div>
          </div>
          <div class="col">
            <h3><b><I>SeaEval</I> for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning</b></h3>
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col text-justify">
            <br>
            <h4><b>Abstract</b></h4>
            <p>We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we examine the brittleness of foundation models in the dimensions of semantics and multilinguality. Our investigations encompasses both open-source and proprietary models, shedding light on their behavior in classic NLP tasks, reasoning, and cultural contexts. Notably, (1) Most models respond inconsistently to paraphrased instructions. (2) Exposure bias pervades, evident in both standard NLP tasks and cultural understanding. (3) For questions rooted in factual, scientific, or common sense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, many models intriguingly demonstrate inconsistent performance on such queries. (4) Models trained multilingually still lack ``balanced multilingual'' capabilities. Our endeavors underscore the need for more generalizable semantic representations and enhanced multilingual contextualization. SeaEval can serve as a launchpad for in-depth investigations for multilingual and multicultural evaluations.</p>
            <h4><b>Biography</b></h4>
            <p>Nancy F. Chen is an A*STAR fellow, senior principal scientist, principal investigator, and group leader at I<sup>2</sup>R (Institute for Infocomm Research) and Principal Investigator at CFAR (Centre for Frontier AI Research). Her group works on generative AI in speech, language, and conversational technology. Her research has been applied to education, defense, healthcare, and media/journalism. Dr. Chen has published 100+ papers and supervised 100+ students/staff. She has won awards from IEEE, Microsoft, NIH, P&G, UNESCO, L’Oréal, SIGDIAL, APSIPA, MICCAI. She is an IEEE SPS Distinguished Lecturer (2023-2024), Program Chair of ICLR 2023, Board Member of ISCA (2021-2025), and Singapore 100 Women in Tech (2021). Technology from her team has led to commercial spin-offs and government deployment. Prior to A*STAR, she worked at MIT Lincoln Lab while doing a PhD at MIT and Harvard. For more info: http://alum.mit.edu/www/nancychen.</p>
          </div>
        </div>
        <br><br>
        <hr>
        <h3 id="speakers-2" class="text-muted">Speech Processing</h3>
        <div class="row">
          <div class="col-8 col-sm-5 col-md-4 col-lg-3">
            <div class="speaker">
              <img src="img/keynote/Peng-Jen.jpg" alt="Speaker Peng-Jen Chen" class="img-fluid">
              <div class="details">
                <h3><a href="https://www.linkedin.com/in/chen-peng-jen-a7a56227">Peng-Jen Chen</a></h3>
                <p>Meta AI</p>
                <div class="social">
                  <a href="https://www.linkedin.com/in/chen-peng-jen-a7a56227" target="_blank"><i class="fa fa-linkedin"></i></a>
                </div>
              </div>
            </div>
          </div>
          <div class="col">
            <h3><b>Building Speech-to-Speech Translation System for English-Hokkien</b></h3>
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col text-justify">
            <br>
            <h4><b>Abstract</b></h4>
            <p>Speech is the primary mode of communication for people who speak languages that lack a standard writing system. With nearly 3000 such unwritten languages in existence, developing speech-to-speech translation technology is critical in overcoming language barriers for these communities. In this talk, we will explore the challenges involved in building a speech-to-speech translation system for English-Taiwanese Hokkien, a real-world language that lacks a widely used standard writing system. We will present our approaches ranging from training data collection and modeling choices, to the evaluation of the developed models.</p>
            <h4><b>Biography</b></h4>
            <p>Peng-Jen Chen is a research engineer at Meta AI. He received a B.S. degree in 2007 and an M.S. degree in 2009 in Computer Science and Information Engineering, at National Taiwan University. He joined Meta as a machine learning engineer in 2012 and joined FAIR as a research engineer in 2018. His key research interests include low-resource machine translation, speech-to-speech translation, speech-text joint pre-training.</p>
          </div>
        </div>
      </div>
    </section>

-->
    <!--==========================
      Special Session Section
    ============================-->
<!--
    <section id="special" class="wow fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Special Session</h2>
          <p>ROCLING 2024 will feature two special sessions that provide a novel topics for participants to know the trend on large language model (LLM).</p>
          <ul>
            <li>
              <a href="#ss1">Special Session 1: Techniques for Large Language Models</a>
            </li>
            <li>
              <a href="#ss2">Special Session 2: Crafting Human-Centered Chatbots: Bridging the Gaps</a>    
            </li>
          </ul>
        </div>
        <div class="card border-dark mb-3" id="ss1">
          <div class="card-header">
            <div class="row justify-content-center align-items-center">
              <h3 class="text-center">Special Session 1:<br> Techniques for Large Language Models</h3>
            </div>
          </div>
          <div class="card-body">
            <h3 class="card-title">我們與語音版 ChatGPT 的距離</h3>
            <div class="row">
              <div class="col">
                <p>
                  <b>李宏毅 Hung-Yi Lee</b><br>
                  Associate Professor, Department of Electrical Engineering and the Department in Computer Science & Information Engineering of National Taiwan University
                </p>
              </div>
            </div>
            <h4 class="card-title">Abstract</h4>
            <div class="row">
              <div class="col">
                <p class="content">在過去的幾個月裡，大型語言模型如ChatGPT的能力已經引起了大眾的廣泛討論和驚嘆，這些語言模型具有通用的處理能力，僅需給予正確的指令，往往就可以完成任務。然而，我們與語音版的ChatGPT的距離還有多遠？我們還缺少什麼才能實現語音版的ChatGPT的誕生？在這場演講中，我將分享一系列可能引領我們走向語音版ChatGPT的最新研究成果，並探討目前的挑戰、潛在的解決方案，讓我們一起攜手迎接由語音版ChatGPT帶來的未來新紀元。
                </p>
              </div>
            </div>
          
            <hr>
          
            <h3 class="card-title">Towards Human-Like Conversational AI</h3>
            <div class="row">
              <div class="col">
                <p>
                  <b>陳縕儂 Yun-Nung Chen</b><br>
                  Associate Professor, Department of Computer Science and Information Engineering in National Taiwan University
                </p>
              </div>
            </div>
            <h4 class="card-title">Abstract</h4>
            <div class="row">
              <div class="col">
                <p class="content">
                  This talk explores two crucial dimensions of Conversational AI: improved understanding and enhanced interaction. The talk will begin with a focus on refining language comprehension through the mitigation of speech recognition errors, ultimately facilitating a more comprehensive understanding of user inputs. Next, we tackle the challenge of scalability, uncovering strategies to maximize the utility of limited dialogue data, thereby enabling adaptive conversational models. Finally, we explore the realm of enriched interaction by seamlessly integrating recommendation systems into conversational interfaces. In sum, These dimensions collectively showcase the potential for substantial progress in Conversational AI, offering valuable insights for future research and innovation in the field.
                </p>
              </div>
            </div>
            <h4 class="card-title">Biography</h4>
            <div class="row">
              <div class="col">
                <p class="content">
                  Yun-Nung (Vivian) Chen is currently an associate professor in the Department of Computer Science & Information Engineering at National Taiwan University. She earned her Ph.D. degree from Carnegie Mellon University, where her research interests focus on spoken dialogue systems and natural language processing. She was recognized as the Taiwan Outstanding Young Women in Science and received Google Faculty Research Awards, Amazon AWS Machine Learning Research Awards, MOST Young Scholar Fellowship, and FAOS Young Scholar Innovation Award. Her team was selected to participate in the first Alexa Prize TaskBot Challenge in 2021. Prior to joining National Taiwan University, she worked in the Deep Learning Technology Center at Microsoft Research Redmond.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="card border-dark mb-3" id="ss2">
          <div class="card-header">
            <div class="row justify-content-center align-items-center">
              <h3 class="text-center">Special Session 2: <br>Crafting Human-Centered Chatbots: Bridging the Gaps</h3>
            </div>
          </div>
          <div class="card-body">
            <div class="row">
              <div class="col">
                <p class="content">
                  Natural language processing (NLP) technology has advanced by leaps and bounds, and chatGPT has been widely loved by netizens since it was launched on the market since last November. Due to the shortage of manpower, the need for dialogue systems is greater than ever. However, creating a dialogue system that can interact with users in accordance with given tasks (such as syllabus, medical orders, health education) is still a considerable challenge. When an agent is given a certain task (such as teaching goal or consulting), how to guide the user to complete the goal requires more human-centered design thinking. "Crafting Human-Centered Chatbots: Bridging the Gaps" forum serves as a gathering place for professionals, researchers, and enthusiasts passionate about the development and deployment of chatbots. Here, we will explore the intricacies of designing chatbots that bridge the gaps between technology and human engagement.
                </p>
                <h4><b></b></h4>
                <p class="content"></p>
              </div>
            </div>
            <h3 class="card-title">Chair</h3>
            <div class="row">
              <div class="col">
                <p>
                  <b>張嘉惠 Chia-Hui Chang</b><br>
                  Professor, Department of Computer Science and Information Engineering in National Central University
                </p>
                <hr>
              </div>
            </div>
          </div>
          <div class="card-body">
            <h3 class="card-title">Panelists</h3>
            <h4 class="card-title">心理諮商對話系統的開發</h4>
            <div class="row">
              <div class="col">
                <p>
                  <b>簡仁宗 Jen-Tzung Chien</b><br>
                  Chair Professor, Institute of Electrical and Computer Engineering in National Yang Ming Chiao Tung University
                </p>
                <hr>
              </div>
            </div>
            <h4 class="card-title">沉浸式視覺設計互動系統</h4>
            <div class="row">
              <div class="col">
                <p>
                  <b>古倫維 Lun-Wei Ku</b><br>
                  Research Fellow/Professor, Institute of Information Science in Academia Sinica
                </p>
              </div>
            </div>
            <h4 class="card-title">教育類型對話系統的開發</h4>
            <div class="row">
              <div class="col">
                <p>
                  <b>劉晨鐘 Chen-Chung Liu</b><br>
                  Chair Professor, Department of Computer Science and Information Engineering at National Central University
                </p>
                <hr>
              </div>
            </div>
            <h4 class="card-title">從物理課的虛擬助教到人社領域的指令工程：AIGC應用於清華大學的嘗試</h4>
            <div class="row">
              <div class="col">
                <p>
                  <b>王道維 Daw-Wei Wang</b><br>
                  Director of Counselling Center, and Vice Director of Center for Application and Development of AI in HSS<br>
                  Professor in Physics Department, National Tsing-Hua University
                </p>
                <hr>
              </div>
            </div>
        </div>
      </div>
    </section>
-->

    <!--==========================
      AI Tutorial Section
    ============================-->
<!--
    <section id="tutorial" class="wow fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>AI Tutorial</h2>
          <p>ROCLING 2024 will include two AI tutorials that offer participants new insights into the latest trends in Graph Neural Network (GNN).</p>
          <ul>
            <li>
              <a href="#ai1">AI Tutorial I: Demystifying Graph Neural Networks: Essentials, Applications, and Trends</a>
            </li>
            <li>
              <a href="#ai2">AI Tutorial II: Chaining Language and Knowledge Resources with LLM(s)</a>    
            </li>
          </ul>
        </div>

        <div class="card border-dark mb-3" id="ai1">
          <div class="card-header">
            <div class="row justify-content-center align-items-center">
              <h3 class="text-center">AI Tutorial I:<br>Demystifying Graph Neural Networks: Essentials, Applications, and Trends</h3>
            </div>
          </div>
          <div class="card-body">
            <div class="row">
              <div class="col">
                <p>
                  <b>李政德 Cheng-Te Li</b><br>
                  Professor, Institute of Data Science and Department of Statistics of National Cheng Kung University
                </p>
              </div>
            </div>
          </div>
        </div>

        <div class="card border-dark mb-3" id="ai2">
          <div class="card-header">
            <div class="row justify-content-center align-items-center">
              <h3 class="text-center">AI Tutorial II:<br>Chaining Language and Knowledge Resources with LLM(s)</h3>
            </div>
          </div>
          <div class="card-body">
            <div class="row">
              <div class="col">
                <p>
                  <b>謝舒凱 Shu-Kai Hsieh</b><br>
                  Professor, Graduate Institute of Linguistics &Graduate Institute of Brain and Mind, College of MedicineNational Taiwan University
                </p>
              </div>
            </div>
            <h4 class="card-title">Abstract</h4>
            <div class="row">
              <div class="col">
                Language and knowledge resources digitally embody human conceptual knowledge and have always played a pivotal role in natural language understanding. With the rise of large language models, the relationship between language resources and these models has emerged as a topic worthy of exploration. This tutorial will introduce the basic concepts of both and delve into their potential interconnections and applications. Moreover, from a practical standpoint, we will provide a hands-on notebook to guide participants in experiencing how to connect the two using the 'langchain' framework.
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--==========================
      Registration Section
    ============================-->
    <section id="buy-registrations" class="section-with-bg fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Registrations</h2>
          <p class="text-muted">Time Zone: UTC/GMT +08:00 (Asia/Taipei)</p>
        </div>
        <div class="row">
          <div class="col-lg-4">
            <div class="card mb-5 mb-lg-3">
              <div class="card-body">
                <h5 class="card-title text-center">Early <br>Registrations</h5>
                <p class="text-highligh text-center">Before October 11, 2024</p>
                <hr>
                <h5 class="text-center">Regular</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 5,000</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 6,000</li>
                </ul>
                <br>
                <h5 class="text-center">Student</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 2,000</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 2,500</li>
                </ul>
                <hr>
                <div class="text-center">
                  <button type="button" class="btn" onclick="window.open('https://conference.iis.sinica.edu.tw/surl/rocling2024/reg','_blank')">Register here</button>
                </div>
              </div>
            </div>
          </div>
          <div class="col-lg-4">
            <div class="card mb-5 mb-lg-3">
              <div class="card-body">
                <h5 class="card-title text-center">Late <br>Registrations</h5>
                <p class="text-center"> October 12 - October 27, 2024</p>
                <hr>
                <h5 class="text-center">Regular</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 5,500</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 6,500</li>
                </ul>
                <br>
                <h5 class="text-center">Student</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 2,500</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 3,000</li>
                </ul>
                <hr>
                <div class="text-center">
                  <button type="button" class="btn" onclick="window.open('https://conference.iis.sinica.edu.tw/surl/rocling2024/reg','_blank')">Register here</button>
                </div>
              </div>
            </div>
          </div>
          <div class="col-lg-4">
            <div class="card mb-5 mb-lg-3">
              <div class="card-body">
                <h5 class="card-title text-center">On-Site <br>Registrations</h5>
                <p class="text-center">November 4 - 5, 2024</p>
                <hr>
                <h5 class="text-center">Regular</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 6,000</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 7,000</li>
                </ul>
                <br>
                <h5 class="text-center">Student</h5>
                <ul class="fa-ul">
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Member: NT$ 3,000</li>
                  <li><span class="fa-li"><i class="fa fa-check"></i></span>ACLCLP Non-Member: NT$ 3,500</li>
                </ul>
                <hr>
                <div class="text-center">
                  <button type="button" class="btn" data-toggle="modal" data-target="#buy-registration-model" data-registration-type="premium-access" disabled>Only on-site registrations</button>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="">
          <div class="">
            <div class="card border-dark mb-3">
              <div class="card-body">
                <h3>註冊說明</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    一般參與者且不具學生身份者需註冊 Regular Fee。一般參與者且具學生身份者可選擇註冊 Student Fee。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    每篇會議論文(包含shared tasks)的發表至少要有一位作者在早鳥註冊截止前繳交<span class="text-highligh">一般報名費</span>
                    (regular fee)。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    報名費含大會午餐、茶點及晚宴，報名費一經繳費後恕不接受退費，會後將郵寄相關資料予報名者。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    ACLCLP Member 為「中華民國計算語言學學會」之有效會員。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    本年度尚未繳交年費之舊會員或失效之會員，與會身份/Category請勾選「….(會員+會費)」，勿再重複申請入會。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    非會員欲同時申請入會者，請先至學會網頁之「會員專區」申請加入會員；報名時「與會身份/Category」請勾選「….(會員+會費)」。<a href="http://www.aclclp.org.tw/member/index.php" target="_blank">(前往會員專區)</a>
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    以「學生新會員」及「學生非會員」身份報名者，請於報名時上傳學生身份證明。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    贊助單位敬請於<span class="text-highligh">10月27日</span>前完成報名手續。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    報名費收據將於會議當日報到時交付。
                  </li>
                </ul>
                <hr>
                <h3>Registration Details</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    A regular fee must be paid by the general participants (not a student).  Students (general participants) can choose to pay the student fee.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Before early registration due, each publication paper (including shared tasks) must have at least one author pay a <span class="text-highligh">regular fee</span>.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Registration fee includes lunches, coffee breaks, and banquet. Registration fees are non-refundable.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    International registrants have to pay by credit card only (Visa or MasterCard). Receipt will be provided on-site.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    A copy of a valid student ID must be uploaded into the system when registering as a student.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Sponsor should be registed before <span class="text-highligh">October 27</span>.
                  </li>
                </ul>
                <hr>
                <h3>報名及繳費期限</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Early Registration: <span class="text-highligh">10/11</span> 以前，報名費應於 <span class="text-highligh">10/17</span> 前繳交。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Late Registration: <span class="text-highligh">10/12</span> 至 <span class="text-highligh">10/27</span> ，報名費應於 10/28  前繳交，線上刷卡繳費者需於 <span class="text-highligh">10/31</span> 前完成繳費。
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    On-Site Registration: 10/27  線上報名截止，擬參加者，請至大會現場報名。
                  </li>
                </ul>
                <hr>
                <h3>Important Dates for Registration</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Early Registration due by <span class="text-highligh">October 11</span>. Payment must be received before <span class="text-highligh">October 17</span>.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Registration between <span class="text-highligh">October 12</span> and <span class="text-highligh">October 27</span>. 
					Payment must be received before <span class="text-highligh">October 31</span>.
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    The registration site will be closed on October 27. After that, please register on-site.
                  </li>
                </ul>
                <hr>

                <h3>Methods of Payment</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    郵政劃撥/Postal
                    <br>
                    戶名：中華民國計算語言學學會
                    <br>
                    帳號：19166251
                    <br>同一單位多位報名者可合併劃撥，請於劃撥通訊欄中註明「ROCLING及註冊編號或報名者姓名」
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    線上刷卡繳費/credit card on-line。
                  </li>
                </ul>
                <hr>
                <h3>For registration inquiries, please contact</h3>
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    聯絡人：何婉如 小姐（中華民國計算語言學學會/ACLCLP）
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    E-mail：<a href="mailto:aclclp@aclclp.org.tw">aclclp@aclclp.org.tw</a>
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    Phone Number: 02-27881638
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!--==========================
      Organization Section
    ============================-->
    <section id="organization" class="wow fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Organization</h2>
        </div>
<!--
        <h3>Honorary Chair</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3  d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/潘維大.jpg">
                </div>
                <p><span class="chair">Wei-Ta Pan</span><br>Soochow University</p>
              </div>
            </div>
          </div>
        </div>
        <br>
        <br>
-->
        <h3>Conference Chairs</h3>
<div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/tseng.jpg">
                </div>
                <p><span class="chair"><a href="https://www.ling.sinica.edu.tw/main/zh-tw?act=researcher_manager&code=show_member&memberID=5" target="_blank">Shu-Chuan Tseng</a></span><br>Academia Sinica<br><a href="mailto:tsengsc@gate.sinica.edu.tw?subject:[ROCLING 2024] Quesions">tsengsc@gate.sinica.edu.tw</a></p>
              </div>
 
           </div>
          </div>
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/曹昱.jpg">
                </div>
                <p><span class="chair"><a href="https://www.citi.sinica.edu.tw/pages/yu.tsao/index_zh.html" target="_blank">Yu Tsao</a></span><br>Academia Sinica<br><a href="mailto:yu.tsao@citi.sinica.edu.tw?subject:[ROCLING 2024] Quesions">yu.tsao@citi.sinica.edu.tw</a></p>
              </div>
 
           </div>
          </div>
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/黃瀚萱.png" style="height: 130%;">
                </div>
                <p><span class="chair"><a href="https://homepage.iis.sinica.edu.tw/pages/hhhuang/index_zh.html" target="_blank">Hen-Hsen Huang</a></span><br>Academia Sinica<br><a href="mailto:hhhuang@iis.sinica.edu.tw?subject:[ROCLING 2024] Quesions">hhhuang@iis.sinica.edu.tw</a></p>
              </div>
 
           </div>
          </div>
        </div>
        <br>
        <br>
        <h3>Program Chairs</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/fan.jpg" style="height: 130%;">
                </div>
                <p><span class="chair"><a href="https://yfan.nlpnchu.org" target="_blank">Yao-Chung Fan</a></span><br>National Chung Hsing University<br><a href="mailto:yfan@nchu.edu.tw?subject:[ROCLING 2024] Quesions">yfan@nchu.edu.tw</a></p>
              </div>
            </div>
          </div>
        </div>
        <br>
        <br>
        <h3>Keynote Chair</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/chang.jpg">
                </div>
                <p><span class="chair">
                <a href="https://staff.csie.ncu.edu.tw/chia/" target="_blank">Chia-Hui Chang</a></span><br>National Central University<br><a href="mailto:chia@csie.ncu.edu.tw?subject:[ROCLING 2024] Quesions">chia@csie.ncu.edu.tw</a></p>
              </div>
            </div>
          </div>
        </div>
        <br>
        <br>
        <!--
        <h3>Special Session Chair</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/張嘉惠.jpeg">
                </div>

                <p><span class="chair"><a href="http://www.csie.ncu.edu.tw/~chia/" target="_blank">Chia-Hui Chang</a></span><br>National Central University<br><a href="mailto:chiahui@g.ncu.edu.tw?subject:[ROCLING 2024] Quesions">chiahui@g.ncu.edu.tw</a></p>
              </div>
            </div>
          </div>
        </div>
        <br>
        <br>
-->
<!--
        <h3>Shared Task Chairs</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/李龍豪.png">
                </div>
                <p><span class="chair"><a href="https://lunghao.weebly.com/" target="_blank">Lung-Hao Lee</a></span><br>National Yang Ming Chiao Tung University<br><a href="mailto:lhlee@nycu.edu.tw?subject:[ROCLING 2024] Quesions">lhlee@nycu.edu.tw</a></p>
              </div>
            </div>
          </div>
--->
<!--
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/yuan-Fuliao.png">
                </div>
                <p><span class="chair"><a href="https://sites.google.com/nycu.edu.tw/speechlabx/prof-yuan-fu-liao?authuser=0" target="_blank">Yuan-Fu Liao</a></span><br>National Yang Ming Chiao Tung University<br><a href="mailto:yfliao@nycu.edu.tw?subject:[ROCLING 2024] Quesions">yfliao@nycu.edu.tw</a></p>
              </div>
            </div>
          </div>
        </div>
        <br>
        <br>
        <h3>AI Tutorial Chair</h3>
        <div class="row">
          <div class="col">
            <div class="row">
              <div class="col py-3 d-flex align-items-center">
                <div class="image">
                  <img src="img/organization/馬偉雲.jpeg">
                </div>
                <p><span class="chair"><a href="https://homepage.iis.sinica.edu.tw/pages/ma/index_zh.html" target="_blank">Wei-Yun Ma</a></span><br>Academia Sinica<br><a href="mailto:ma@iis.sinica.edu.tw?subject:[ROCLING 2024] Quesions">ma@iis.sinica.edu.tw</a></p>
              </div>
            </div>
          </div>

        </div>
--->
        <br>
        <br>
        <h3>Organized by</h3>
        <div class="organized row">
          <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
              <a href="https://www.sinica.edu.tw" target="_blank"><img src="img/organization/logo-sinica.png"></a>
              <br>Academia Sinica
            </div>
          </div>
          <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
              <a href="https://www.aclclp.org.tw" target="_blank"><img src="img/organization/aclclp2.png"></a>
              <br>The Association for Computational Linguistics and Chinese Language Processing
            </div>
          </div>
          <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
              <a href="https://www.ling.sinica.edu.tw" target="_blank"><img src="img/organization/logo-ling.png"></a>
            </div>
          </div>
          <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
            </div>
          </div>
   		  <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
              <a href="https://www.citi.sinica.edu.tw" target="_blank"><img src="img/organization/logo-citi.png"></a>
            </div>
          </div>
          <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
            </div>
          </div>
		  <div class="col-md-10 col-lg-5 py-4">
            <div class="organizedBy_image">
              <a href="https://www.iis.sinica.edu.tw" target="_blank"><img src="img/organization/logo-iis.png"></a>
            </div>
          </div>

        </div>
        <br><br>
        
      </div>
    </section>

    <!--==========================
      Venue Section
    ============================-->
    <section id="venue" class="section-with-bg fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Conference Venue</h2>
          <p>Conference venue location info and gallery</p>
        </div>
        <div class="row">
          <div class="col-lg-6 venue-map">
<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d1290.3819214577977!2d121.6120633058433!3d25.041413298791138!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3442ab46b3aaaaab%3A0x6ad0b8243ddc70ef!2sHumanities%20and%20Social%20Science%20Building!5e0!3m2!1sen!2stw!4v1718221977258!5m2!1sen!2stw" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
          </div>
          <div class="col-lg-6 venue-info venue-info-img1">
            <div class="row justify-content-center">
              <div class="col-11 col-lg-11">
                <h3></h3>
                <h3>Humanities and Social Science Building (HSSB), Academia Sinica.</h3>
				<p>No. 128, Sec. 2, Academia Rd., Taipei, Taiwan 11529<br/>
				<a href="https://www.sinica.edu.tw/en/Paragraph/10">Transportation</a></p>
                <h3>中央研究院人文社會科學館</h3>
                <p>11529 台北市南港區研究院路二段128號<br/> 
				<a href="https://www.sinica.edu.tw/Paragraph/10">交通資訊</a></p>
				<br/>
                <p><a href="https://maps.app.goo.gl/KA58akfRtiFHbN6F6" target="_blank">https://maps.app.goo.gl/KA58akfRtiFHbN6F6</a></p>

                <br>
              </div>
            </div>
          </div>
        </div>
<!--
        <div class="row">
          <div class="col-lg-6 venue-info venue-info-img2">
            <div class="row justify-content-center">
              <div class="col-11 col-lg-11">
                <h3>By City Buses</h3>
                <ul class="fa-ul text-white">
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    255, 268, 304, 620, 645, minibuses 18 and 19, red 30 —Soochow University_Ch'ien Mu House stop
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-check"></i></span>
                    557 —Soochow University stop
                  </li>
                </ul>
                <h3>By MRT</h3>
                <ul class="fa-ul text-white">
                 <li>
                   <span class="fa-li"><i class="fa fa-check"></i></span>
                   Shihlin stop, transfer buses 255, 304, 620, minibuses 18 and 19, red 30 —Soochow University stop
                 </li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-lg-6 venue-info venue-info-img3">
            <div class="row justify-content-center">
              <div class="col-11 col-lg-11">
                <h3>By Train</h3>
                <ul class="fa-ul text-white">
                 <li>
                   <span class="fa-li"><i class="fa fa-check"></i></span>
                   Taipei Station, transfer MRT to Shihlin stop, transfer buses 255, 304, 620, minibuses 18 and 19, red 30 — Soochow University stop
                 </li>
                </ul>
                <h3>By Self Driving</h3>
                <ul class="fa-ul text-white">
                 <li>
                   <span class="fa-li"><i class="fa fa-check"></i></span>
                   Sun Yat-sen Highway → Chongqing N. Rd. interchange (to Shihlin)→ Chongqing N. Rd. Sec. 4 → Bailing Bridge → Zhongzheng Rd. →Fulin Rd. → Zhishan Rd. → Waishuangsi Campus
                 </li>
                 <li>學校停車場無對外面開放，請多加利用大眾交通工具</li>
                 <li>學校周圍於至善路設有路邊公有停車格</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid venue-gallery-container">
          <div class="row justify-content-center">
            <div class="col-lg-6 col-md-6 text-center">
              <div class="venue-gallery">
                <img src="img/shilin.gif" alt="" class="img-fluid">
              </div>
            </div>
            <div class="col-lg-6 col-md-6 text-center">
              <div class="venue-gallery">
                <img src="img/jianan.gif" alt="" class="img-fluid">
              </div>
            </div>
          </div>
        </div>
      </div>
	-->
    </section>


    <!--==========================
      Sponsors Section
    ============================-->
    <section id="sponsors" class="wow fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Sponsors</h2>
        </div>
        <div class="row no-gutters sponsors-wrap clearfix">
         <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://iis.sinica.edu.tw/zh/index.html" target="_blank">
                <img src="img/sponsors/logo-iis.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.citi.sinica.edu.tw" target="_blank">
                <img src="img/sponsors/logo-citi.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.itri.org.tw/" target="_blank">
                <img src="img/sponsors/itri-logo.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.deltaww.com/" target="_blank">
                <img src="img/sponsors/Delta-logo.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
        <div class="row no-gutters sponsors-wrap clearfix">
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.eland.com.tw/" target="_blank">
                <img src="img/sponsors/eLAND-logo.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.cht.com.tw/home/consumer" target="_blank">
                <img src="img/sponsors/chunghwa.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.cyberon.com.tw/" target="_blank">
                <img src="/img/sponsors/cyberon.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <!--
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.nstc.gov.tw/" target="_blank">
                <img src="img/sponsors/1.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
 
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.cyberon.com.tw/" target="_blank">
                <img src="img/sponsors/2.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
        </div>
                  <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.iii.org.tw/" target="_blank">
                <img src="img/sponsors/iii_logo.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
         <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="http://www.ez-ai.com.tw/" target="_blank">
                <img src="img/sponsors/ezai.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
        </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.tmnewa.com.tw/" target="_blank">
                <img src="img/sponsors/tm_newa_combined_1_rgb_l.jpg" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="https://www.esunbank.com/zh-tw/personal" target="_blank">
                <img src="img/sponsors/esun.png" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          <div class="col-lg-3 col-md-4 col-xs-6">
            <div class="sponsor-logo">
              <a href="http://ai.scu.edu.tw/" target="_blank">
                <img src="img/sponsors/AI_logo.gif" class="img-fluid" alt="">
              </a>
            </div>
          </div>
          -->
        </div>
      </div>
    </section>

    <!--==========================
      Hotels Section
    ============================-->
<!--
    <section id="hotels" class="section-with-bg fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>Hotel</h2>
          <p>Here are some nearby hotels</p>
        </div>
        <div class="row">
          <div class="col-lg-4 col-md-6">
            <div class="hotel">
              <div class="hotel-img">
                <img src="img/hotels/soochow.jpg" alt="東吳大學 學人招待所" class="img-fluid">
              </div>
              <h3><a href="https://guesthouse.inv.scu.edu.tw" target="_blank">東吳大學學人招待所</a></h3>
              <div class="stars">
                <i class="fa fa-thumbs-up"></i>
                <i class="fa fa-thumbs-up"></i>
                <i class="fa fa-thumbs-up"></i>
                <i class="fa fa-thumbs-up"></i>
                <i class="fa fa-thumbs-up"></i>
              </div>
              <div class="infomation">
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-map"></i></span>No.70, Linhsi Road, Shihlin District, Taipei City 111, Taiwan<br><span class="small">台北市士林區臨溪路70號</span>
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-street-view"></i></span>0.0 km from the Venue
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-lg-4 col-md-6">
            <div class="hotel">
              <div class="hotel-img">
                <img src="img/hotels/renaissance.jpg" alt="台北士林萬麗酒店" class="img-fluid">
              </div>
              <h3><a href="https://www.gobooking.com.tw/Renaissance/ShihlinTaipei" target="_blank">Renaissance Taipei Shihlin Hotel<br><span class="small">台北士林萬麗酒店</span></a></h3>
              <div class="stars">
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
              </div>
              <div class="infomation">
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-map"></i></span>No. 8 Ln. 470, Section 5, Zhongshan North Road, Shilin District, Taipei City 111, Taiwan<br><span class="small">台北市士林區中山北路五段470巷8號</span>
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-street-view"></i></span>1.7 km from the Venue
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-lg-4 col-md-6">
            <div class="hotel">
              <div class="hotel-img">
                <img src="img/hotels/mayfull.jpeg" alt="台北美福大飯店" class="img-fluid">
              </div>
              <h3><a href="https://www.grandmayfull.com" target="_blank">Grand Mayfull Hotel Taipei<br><span class="small">台北美福大飯店</span></a></h3>
              <div class="stars">
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
                <i class="fa fa-star"></i>
              </div>
              <div class="infomation">
                <ul class="fa-ul">
                  <li>
                    <span class="fa-li"><i class="fa fa-map"></i></span>No.55, Lequn 2nd Rd., Zhongshan Dist., Taipei 10462, Taiwan<br><span class="small">台北市中山區樂群二路55號</span>
                  </li>
                  <li>
                    <span class="fa-li"><i class="fa fa-street-view"></i></span>3.3 km from the Venue
                  </li>
                </ul>
              </div>
            </div>
          </div>

        </div>
      </div>
    </section>
-->
    <!--==========================
      F.A.Q Section
    ============================-->
<!--
    <section id="faq" class="wow fadeInUp">
      <div class="container">
        <div class="section-header">
          <h2>F.A.Q</h2>
        </div>
        <div class="row justify-content-center">
          <div class="col-lg-9">
              <ul id="faq-list">
                <li>
                  <a data-toggle="collapse" class="collapsed" href="#faq1">
                    如果一次投稿多篇文章，該如何報名？
                    <span class="eng-content">How do I register if I submit multiple articles at once?</span>
                    <i class="fa fa-minus-circle"></i>
                  </a>
                  <div id="faq1" class="collapse" data-parent="#faq-list">
                    <p>
                      每一篇投稿文章都必須至少有一名作者進行 Regular Register。也就是說，若您投稿兩篇文章，則必須分別為這兩篇文章進行 Regular Register。
                    </p>
                    <p class="eng-content">
                      There must be at least one author registered under the Regular registraction for each article submitted. As an example, if you submit two articles, both must be registered under the "Regular" registraction. 
                    </p>
                  </div>
                </li>
                <li>
                  <a data-toggle="collapse" class="collapsed" href="#faq2">
                    中華民國計算語言學學會是什麼？如果我要註冊 ROCLING 2024 一定要註冊中華民國計算語言學學會嗎?
                    <span class="eng-content">What is ACLCLP Member? For ROCLING 2024, do I need to register as an ACLCLP member?</span>
                    <i class="fa fa-minus-circle"></i>
                  </a>
                  <div id="faq2" class="collapse" data-parent="#faq-list">
                    <p class="faq-content">
                      有關「中華民國計算語言學學會」之介紹與註冊請洽<a href="https://www.aclclp.org.tw/member/index.php" target="_blank">學會官網</a>。若您不是學會成員也可以註冊 ROCLING 2024，詳情請參考<a href="#buy-registrations">註冊資訊</a>。
                    </p>
                    <p class="eng-content">
                      For information and registration regarding the ACLCLP member, please visit the <a href="https://www.aclclp.org.tw/member/index.php" target="_blank">official website of the ACLCLP</a>. You can still register for ROCLING 2024 even if you aren't a member of the ACLCLP. For more details, please refer to the <a href="#buy-registrations">registration information</a>.
                    </p>
                  </div>
                </li>
                <li>
                  <a data-toggle="collapse" class="collapsed" href="#faq3">
                    我該如何繳交註冊費用？
                    <span class="eng-content">How can I pay the registration fee?</span>
                    <i class="fa fa-minus-circle"></i>
                  </a>
                  <div id="faq3" class="collapse" data-parent="#faq-list">
                    <p class="faq-content">
                      您可以使用郵政劃撥或是線上刷卡繳費，詳情請參考<a href="#buy-registrations">註冊資訊</a>。
                    </p>
                    <p class="eng-content">
                      You can pay via postal transfer or credit card online.Please refer to the <a href="#buy-registrations">registration information</a> for specific instructions.
                    </p>
                  </div>
                </li>
                <li>
                  <a data-toggle="collapse" class="collapsed" href="#faq4">
                    如果我還有疑問該詢問誰？
                    <span class="eng-content">If I have any questions, who should I contact?</span>
                    <i class="fa fa-minus-circle"></i>
                  </a>
                  <div id="faq4" class="collapse" data-parent="#faq-list">
                    <ul class="faq-content">
                      <li>註冊相關疑問，請聯絡何婉如小姐/Email: <a href="mailto:aclclp@aclclp.org.tw">aclclp@aclclp.org.tw</a>/Phone Number: 02-27881638。</li>
                      <li>Shared Task I 相關疑問，請寄信至 <a href="mailto:rocling23-shared-task@googlegroups.com">rocling23-shared-task@googlegroups.com</a>。</li>
                      <li>Shared Task II 相關疑問，請聯絡:
                        <ul>
                          <li>楊小姐/Email: <a href="mailto:m31221123@nycu.edu.tw">m31221123@nycu.edu.tw</a>/Phone Number: 03-5712121#54554</li>
                          <li>白小姐/Email: <a href="mailto:pehsimju@nycu.edu.tw">pehsimju@nycu.edu.tw</a>/Phone Number: 03-5712121#54555</li>
                        </ul>
                      </li>
                      <li>投稿與其他疑問，請寄信至 <a href="mailto:rocling2023@gmail.com">rocling2023@gmail.com</a>。</li>
                    </ul>
                    <ul class="eng-content">
                      <li>For registration inquiries, please contact Ms. Ho at Email: <a href="mailto:aclclp@aclclp.org.tw">aclclp@aclclp.org.tw</a>/Phone Number: 02-27881638.</li>
                      <li>For Shared Task I, please reach out to <a href="mailto:rocling23-shared-task@googlegroups.com">rocling23-shared-task@googlegroups.com</a>.</li>
                      <li>For Shared Task II, please contact:
                        <ul>
                          <li>Ms. Yang at Email: <a href="mailto:m31221123@nycu.edu.tw">m31221123@nycu.edu.tw</a>/Phone Number: 03-5712121#54554.</li>
                          <li>Ms. Bai at Email: <a href="mailto:pehsimju@nycu.edu.tw">pehsimju@nycu.edu.tw</a>/Phone Number: 03-5712121#54555.</li>
                        </ul>
                      </li>
                      <li>For submission and other questions, please contact to <a href="mailto:rocling2023@gmail.com">rocling2023@gmail.com</a>.</li>
                    </ul>
                  </div>
                </li>
              </ul>
          </div>
        </div>
      </div>
    </section>
-->

  </main>


  <!--==========================
    Footer
  ============================-->
  <footer id="footer">
    <div class="footer-top">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-4 col-md-6 footer-info">
<!--            <img src="img/rocling-2023-logo-color.png" alt="ROCLING 2024"> -->
            <p class="">The 36th annual Conference on Computational Linguistics and Speech Processing (ROCLING 2024) will be held in Academia Sinica, Taipei City, Taiwan from November 4-5, 2024.</p>
          </div>
          <div class="col-lg-4 col-md-3 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="fa fa-angle-right"></i> <a href="https://www.sinica.edu.tw" target="_blank">Academia Sinica</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="https://www.aclclp.org.tw" target="_blank">ACLCLP</a></li>
            </ul>
          </div>
          <div class="col-lg-4 col-md-6 footer-contact">
            <h4>Contact Us</h4>
            <p>
              115201 台北市南港區研究院路二段128號<br>
              128 Academia Road, Section 2, Nankang, Taipei 115201, Taiwan<br>
              Email: <a href="mailto:hhhuang@iis.sinica.edu.tw">hhhuang@iis.sinica.edu.tw</a><br>
            </p>
            <div class="social-links d-none">
              <a href="#" class="twitter"><i class="fa fa-twitter"></i></a>
              <a href="#" class="facebook"><i class="fa fa-facebook"></i></a>
              <a href="#" class="instagram"><i class="fa fa-instagram"></i></a>
              <a href="#" class="google-plus"><i class="fa fa-google-plus"></i></a>
              <a href="#" class="linkedin"><i class="fa fa-linkedin"></i></a>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
<!--
        &copy; Copyright <script>document.write(new Date().getFullYear());</script> <a href="https://nlp.bigdata.scu.edu.tw"><strong>SCU NLP LAB</strong></a>, All Rights Reserved.
-->
      </div>
      <div class="credits">
        <!--
          All the links in the footer should remain intact.
          You can delete the links only if you purchased the pro version.
          Licensing information: https://bootstrapmade.com/license/
          Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=TheEvent
        -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
        Photo by <a href="https://unsplash.com/@louis_cheng?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Louis Cheng</a> on <a href="https://unsplash.com/s/photos/taipei?orientation=landscape&utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
      </div>
    </div>
  </footer><!-- #footer -->

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js"></script>

  <script>
  const imageUrls = ['2T1A0930.jpg', '2T1A1200.jpg', '2T1A1301.jpg', 
                     '2T1A1556.jpg', '2T1A2105.jpg', 'DSC02088.jpg', 'DSC02566.jpg', 
                     'DSC02693.jpg', '2T1A0591.jpg', '2T1A0952.jpg', '2T1A1217.jpg',
                     '2T1A1302.jpg', '2T1A1567.jpg', '2T1A2112.jpg', 'DSC02196.jpg', 
                     'DSC02575.jpg', 'DSC02699.jpg', '2T1A0596.jpg', '2T1A0955.jpg', 
                     '2T1A1225.jpg', '2T1A1306.jpg', '2T1A1642.jpg', '2T1A2123.jpg', 
                     'DSC02216.jpg', 'DSC02583.jpg', 'DSC02733.jpg', '2T1A0601.jpg', 
                     '2T1A0957.jpg', '2T1A1227.jpg', '2T1A1320.jpg', '2T1A1649.jpg', 
                     '2T1A2128.jpg', 'DSC02262.jpg', 'DSC02589.jpg', 'DSC02736.jpg', 
                     '2T1A0604.jpg', '2T1A0981.jpg', '2T1A1235.jpg', '2T1A1325.jpg', 
                     '2T1A1659.jpg', '2T1A2132.jpg', 'DSC02312.jpg', 'DSC02595.jpg', 
                     'DSC02775.jpg', '2T1A0605.jpg', '2T1A1013.jpg', '2T1A1242.jpg', 
                     '2T1A1327.jpg', '2T1A1733.jpg', '2T1A2139.jpg', 'DSC02392.jpg', 
                     'DSC02599.jpg', 'DSC02804.jpg', '2T1A0651.jpg', '2T1A1016.jpg', 
                     '2T1A1247.jpg', '2T1A1336.jpg', '2T1A1743.jpg', '2T1A2147.jpg', 
                     'DSC02400.jpg', 'DSC02608.jpg', 'DSC02834.jpg', '2T1A0655.jpg', 
                     '2T1A1021.jpg', '2T1A1250.jpg', '2T1A1342.jpg', '2T1A1774.jpg', 
                     '2T1A2155.jpg', 'DSC02415.jpg', 'DSC02612.jpg', 'DSC02890.jpg', 
                     '2T1A0659.jpg', '2T1A1034.jpg', '2T1A1261.jpg', '2T1A1357.jpg', 
                     '2T1A1842.jpg', '2T1A2170.jpg', 'DSC02461.jpg', 'DSC02615.jpg', 
                     'DSC02901.jpg', '2T1A0721.jpg', '2T1A1067.jpg', '2T1A1263.jpg', 
                     '2T1A1374.jpg', '2T1A1872.jpg', '2T1A2174.jpg', 'DSC02472.jpg', 
                     'DSC02620.jpg', 'DSC02904.jpg', '2T1A0726.jpg', '2T1A1075.jpg', 
                     '2T1A1268.jpg', '2T1A1382.jpg', '2T1A1893.jpg', '2T1A2186.jpg', 
                     'DSC02487.jpg', 'DSC02624.jpg', 'DSC02919.jpg', '2T1A0757.jpg', 
                     '2T1A1093.jpg', '2T1A1278.jpg', '2T1A1390.jpg', '2T1A1896.jpg', 
                     '2T1A2210.jpg', 'DSC02496.jpg', 'DSC02628.jpg', 'DSC02933.jpg', 
                     '2T1A0802.jpg', '2T1A1106.jpg', '2T1A1283.jpg', '2T1A1392.jpg', 
                     '2T1A1943.jpg', '2T1A2221.jpg', 'DSC02523.jpg', 'DSC02636.jpg', 
                     'DSC02941.jpg', '2T1A0817.jpg', '2T1A1126.jpg', '2T1A1287.jpg', 
                     '2T1A1410.jpg', '2T1A2056.jpg', '2T1A2227.jpg', 'DSC02547.jpg', 
                     'DSC02641.jpg', 'DSC02955.jpg', '2T1A0863.jpg', '2T1A1133.jpg', 
                     '2T1A1288.jpg', '2T1A1442.jpg', '2T1A2061.jpg', '2T1A3675.jpg', 
                     'DSC02550.jpg', 'DSC02647.jpg', 'DSC02965.jpg', '2T1A0866.jpg', 
                     '2T1A1140.jpg', '2T1A1296.jpg', '2T1A1453.jpg', '2T1A2064.jpg', 
                     '2T1A3701.jpg', 'DSC02552.jpg', 'DSC02651.jpg', 'DSC02982.jpg', 
                     '2T1A0915.jpg', '2T1A1148.jpg', '2T1A1298.jpg', '2T1A1489.jpg', 
                     '2T1A2075.jpg', '2T1A3707.jpg', 'DSC02557.jpg', 'DSC02661.jpg', 
                     'DSC02986.jpg', '2T1A0918.jpg', '2T1A1155.jpg', '2T1A1300.jpg', 
                     '2T1A1534.jpg', '2T1A2079.jpg', '2T1A3710.jpg', 'DSC02561.jpg', 
                     'DSC02665.jpg', 'DSC03646.jpg'];

  var carouselInner = document.getElementById("carouselInner");

  for (var i = 0; i < imageUrls.length; i++) {
    var newCarouselItem = document.createElement("div");
    newCarouselItem.classList.add("carousel-item");

    var newImage = document.createElement("img");
    newImage.src = 'img/photo/'+imageUrls[i];
    newImage.classList.add("d-block", "w-100");
    
    newCarouselItem.appendChild(newImage);
    carouselInner.appendChild(newCarouselItem);
  }
  </script>

</body>

</html>
